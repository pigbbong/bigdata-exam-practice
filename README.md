# ê°œìš”
ë³¸ ì €ì¥ì†ŒëŠ” **ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ëŒ€ë¹„ìš© í•™ìŠµ ì •ë¦¬ ë ˆí¬ì§€í† ë¦¬**ë¡œ,  
ê¸°ì¶œ ë° ì˜ˆìƒ ë¬¸ì œë¥¼ ChatGPTë¥¼ í™œìš©í•´ ì§ì ‘ êµ¬ì„±í•˜ê³ ,  
ê° ë¬¸ì œë³„ ì ‘ê·¼ ë°©ì‹ê³¼ í’€ì´ ê³¼ì •ì„ ê¸°ë¡í•œ ê°œì¸ í•™ìŠµ ì•„ì¹´ì´ë¸Œì…ë‹ˆë‹¤.  

CSV íŒŒì¼ì€ ê°ê° type1(1ìœ í˜•), type2(2ìœ í˜•), type3(3ìœ í˜•) ë””ë ‰í† ë¦¬ì— ìˆìœ¼ë©°, ë‹¤ìš´ë¡œë“œ or ê¹ƒí—ˆë¸Œ ê²½ë¡œë¥¼ ì§€ì •í•˜ê³ , pd.read_csv()ë¥¼ ì‚¬ìš©í•´ ë¶ˆëŸ¬ì™€ ë¬¸ì œ í’€ì´ì— í™œìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

CSV íŒŒì¼ ë²ˆí˜¸ë¥¼ ë¬¸ì œ ë²ˆí˜¸ì— ë§ì¶°ì„œ í‘¸ì‹œë©´ ë©ë‹ˆë‹¤. ex) 1ë²ˆ ë¬¸ì œ -> 1.csv, 6-1, 6-2ë²ˆ ë¬¸ì œ -> 6.csv

ê° ë¬¸ì œë³„ë¡œ ì œê°€ ì§ì ‘ ì‘ì„±í•œ í’€ì´ ì½”ë“œë¥¼ í¬í•¨í•˜ì˜€ìœ¼ë‚˜, ì œ ë°©ì‹ì´ ìœ ì¼í•œ ì •ë‹µì€ ì•„ë‹™ë‹ˆë‹¤.  
ìƒí™©ê³¼ ì ‘ê·¼ ë°©ì‹ì— ë”°ë¼ ë” ë‚˜ì€ ì½”ë“œê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì´ ì €ì¥ì†Œì˜ ì½”ë“œëŠ” í•™ìŠµ ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.


# ğŸ“ 1ìœ í˜•

<details>
<summary><h2>ğŸ“Œ ë¬¸ì œ ëª©ë¡ ë³´ê¸°</h2></summary>

<h3 style="font-weight:normal;">1.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ë¡œ ì‚¬ë§ë¥ ì´ ê°€ì¥ ë†’ì€ ì§ˆë³‘ëª…ì„ êµ¬í•˜ê³ , í•´ë‹¹ ì§ˆë³‘ë“¤ì˜ ì‚¬ë§ììˆ˜ í‰ê· ì„ ì†Œìˆ˜ì  ì²«ë²ˆì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ êµ¬í•˜ì‹œì˜¤. (ì‚¬ë§ë¥  = ì‚¬ë§ììˆ˜ / í™˜ììˆ˜)
</h3>

<details>
<summary>ì½”ë“œ</summary>

df['ì‚¬ë§ë¥ '] = df['ì‚¬ë§ììˆ˜'] / df['í™˜ììˆ˜']<br>
target = df.groupby('ì—°ë„')['ì‚¬ë§ë¥ '].idxmax().values<br>
answer = round(df[df.index.isin(target)]['ì‚¬ë§ììˆ˜'].mean())<br>
answer
<br><br>

>779
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">2.</h3>
<h3 style="font-weight:normal;">
ë„ì‹œ ê±°ì£¼ì ì¤‘ 60ì„¸ ì´ìƒ ë‚¨ì„±ì˜ í‰ê·  ì˜ë£Œë¹„ë¥¼ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ êµ¬í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
target = df[(df['ê±°ì£¼ì§€'] == 'ë„ì‹œ') & (df['ì„±ë³„'] == 'ë‚¨ì„±') & (df['ì—°ë ¹'] >= 60)]<br>
answer = target['ì˜ë£Œë¹„'].mean()<br>
answer

<br><br>
>560229.24
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">3.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ë¡œ ë§¤ì¶œ ìƒìœ„ 2ê°œ ì œí’ˆì˜ ë§¤ì¶œ í•©ê³„ë¥¼ êµ¬í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
target = df.sort_values(by=['ì—°ë„', 'ë§¤ì¶œ'], ascending=[False, False]).groupby('ì—°ë„').head(2)['ë§¤ì¶œ'].sum()<br>
target

<br><br>
>44076
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">4.</h3>
<h3 style="font-weight:normal;">
ëˆ„ì  ì¬ê³ ëŸ‰ì´ ì²˜ìŒìœ¼ë¡œ 5000ì„ ì´ˆê³¼í•œ ì›”ì„ êµ¬í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ì›”'] = pd.to_datetime(df['ì›”'])<br>
df['month'] = df['ì›”'].dt.month<br>
target = df[df['ëˆ„ì ì¬ê³ '] > 5000]['month'].iloc[0]<br>
target
	
<br><br>
>9
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">5.</h3>
<h3 style="font-weight:normal;">
ë¶€ì„œë³„ë¡œ ì—°ë„ë³„ ê¸‰ì—¬ ì¸ìƒë¥ ì˜ í‰ê· ì„ ê³„ì‚°í•œ í›„, ì¸ìƒë¥ ì˜ í¸ì°¨(í‘œì¤€í¸ì°¨)ê°€ ê°€ì¥ ì‘ì€ ë¶€ì„œë¥¼ êµ¬í•˜ì‹œì˜¤.  (ì¦‰, ê°€ì¥ ì¼ê´€ë˜ê²Œ ì¸ìƒë¥ ì´ ë†’ì€ ë¶€ì„œë¥¼ ì°¾ëŠ” ë¬¸ì œ)</h3>

<h4 style="font-weight:normal;">
- ì¸ìƒë¥  = (ì´ë²ˆ í•´ ì—°ë´‰ - ì „ë…„ë„ ì—°ë´‰) / ì „ë…„ë„ ì—°ë´‰
<br>
- ì²« í•´(2018ë…„)ëŠ” ì¸ìƒë¥  ê³„ì‚°ì—ì„œ ì œì™¸
</h4>

<details>
<summary>ì½”ë“œ</summary>
<span style="color:gray;"># ì „ë…„ë„ ì—°ë´‰ ì¶”ê°€ (ë¶€ì„œë³„ shift)</span><br>
df['ì „ë…„ë„ì—°ë´‰'] = df.groupby('ë¶€ì„œ')['ì—°ë´‰'].shift(1)<br><br>

<span style="color:gray;"># ì¸ìƒë¥  ê³„ì‚°</span><br>
df['ì¸ìƒë¥ '] = (df['ì—°ë´‰'] - df['ì „ë…„ë„ì—°ë´‰']) / df['ì „ë…„ë„ì—°ë´‰']<br><br>

<span style="color:gray;"># ê° ë¶€ì„œë³„ ì¸ìƒë¥ ì˜ í‘œì¤€í¸ì°¨ ê³„ì‚°</span><br>
std_by_dept = df.groupby('ë¶€ì„œ')['ì¸ìƒë¥ '].std()<br><br>

<span style="color:gray;"># ì¸ìƒë¥ ì˜ í‘œì¤€í¸ì°¨ê°€ ê°€ì¥ ì‘ì€ ë¶€ì„œ</span><br>
answer = std_by_dept.idxmin()<br>
print("ê°€ì¥ ì¼ì •í•œ ì¸ìƒë¥ ì„ ê°€ì§„ ë¶€ì„œ:", answer)

<br><br>
>ê°€ì¥ ì¼ì •í•œ ì¸ìƒë¥ ì„ ê°€ì§„ ë¶€ì„œ: ì¸ì‚¬ë¶€
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">6-1.</h3>
<h3 style="font-weight:normal;">
ë„ì‹œ ê±°ì£¼ì ì¤‘ 60ì„¸ ì´ìƒ ì—¬ì„±ì˜ ë°©ë¬¸íšŸìˆ˜ í‰ê· ì„ ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‚˜íƒ€ë‚´ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
answer = round(df[(df['ê±°ì£¼ì§€'] == 'ë„ì‹œ') & (df['ì—°ë ¹'] >= 60) & (df['ì„±ë³„'] == 'ì—¬ì„±')]['ë°©ë¬¸íšŸìˆ˜'].mean(), 2)<br>
answer
	
<br><br>
>2.38
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">6-2.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ ì§ˆë³‘ ì‚¬ë§ë¥ ì„ ê³„ì‚°í•˜ê³ , ê·¸ì¤‘ ì‚¬ë§ë¥ ì´ ê°€ì¥ ë†’ì€ ì§ˆë³‘ ì´ë¦„ì„ ì—°ë„, ì§ˆë³‘, ì‚¬ë§ë¥  í˜•íƒœë¡œ ì¶œë ¥í•˜ì‹œì˜¤.  (ì‚¬ë§ë¥  = ì‚¬ë§ì ìˆ˜ / ì „ì²´ í™˜ì ìˆ˜)
</h3>

<details>
<summary>ì½”ë“œ</summary>
<span style="color:gray;"># ì—°ë„-ì§ˆë³‘ë³„ ì „ì²´ í™˜ììˆ˜ì™€ ì‚¬ë§ì ìˆ˜ ê³„ì‚°</span><br>
df_rate = df.groupby(['ì—°ë„', 'ì§ˆë³‘']).agg(<br>
&nbsp;&nbsp;ì‚¬ë§ììˆ˜=('ì‚¬ë§ì—¬ë¶€', 'sum'),<br>
&nbsp;&nbsp;ì¸ì›ìˆ˜=('ì‚¬ë§ì—¬ë¶€', 'count')<br>
).reset_index()<br><br>

<span style="color:gray;"># ì‚¬ë§ë¥  ê³„ì‚°</span><br>
df_rate['ì‚¬ë§ë¥ '] = df_rate['ì‚¬ë§ììˆ˜'] / df_rate['ì¸ì›ìˆ˜']<br><br>

<span style="color:gray;"># ì—°ë„ë³„ ìµœê³  ì‚¬ë§ë¥  ì§ˆë³‘ ì¶”ì¶œ</span><br>
answer = df_rate.sort_values(['ì—°ë„', 'ì‚¬ë§ë¥ '], ascending=[True, False]) \ <br>
&nbsp;&nbsp;.groupby('ì—°ë„').head(1)[['ì—°ë„', 'ì§ˆë³‘', 'ì‚¬ë§ë¥ ']].reset_index(drop=True)<br>
display(answer)

<br><br>
| ì—°ë„ |  ì§ˆë³‘   |  ì‚¬ë§ë¥    |
|:----:|:------:|:---------:|
| 2018 | ê³ í˜ˆì•• | 0.142857  |
| 2019 | ì‹¬ì¥ë³‘ | 0.142857  |
| 2020 |   ì•”   | 0.111111  |
| 2021 | ì‹¬ì¥ë³‘ | 0.133333  |
| 2022 |   ì•”   | 0.111111  |
| 2023 |   ì•”   | 0.166667  |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">7.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ë¡œ, ë°˜í’ˆë¥ ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆëª…ì„ êµ¬í•˜ì‹œì˜¤.  (ë°˜í’ˆë¥  = ë°˜í’ˆëœ ê±´ìˆ˜ / ì „ì²´ ë¦¬ë·° ê±´ìˆ˜)
</h3>

<details>
<summary>ì½”ë“œ</summary>
df_rate = df.groupby(['ì—°ë„', 'ìƒí’ˆ']).agg(ë°˜í’ˆëœê±´ìˆ˜=('ë°˜í’ˆì—¬ë¶€', 'sum'), ë¦¬ë·°ê±´ìˆ˜=('ë°˜í’ˆì—¬ë¶€', 'size')).reset_index()<br>
df_rate['ë°˜í’ˆë¥ '] = df_rate['ë°˜í’ˆëœê±´ìˆ˜'] / df_rate['ë¦¬ë·°ê±´ìˆ˜']<br>
answer = df_rate.sort_values(by=['ì—°ë„', 'ë°˜í’ˆë¥ '], ascending=False).groupby('ì—°ë„').head(1)[['ì—°ë„', 'ìƒí’ˆ']].reset_index(drop=True)<br>
answer
	
<br><br>
| ì—°ë„ |   ìƒí’ˆ   |
|:----:|:-------:|
| 2023 | ìŠ¤ë§ˆíŠ¸í° |
| 2022 | ìŠ¤ë§ˆíŠ¸í° |
| 2021 | ëƒ‰ì¥ê³    |
| 2020 | ë…¸íŠ¸ë¶   |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">8.</h3>
<h3 style="font-weight:normal;">
ê° ê³¼ëª©ë³„ë¡œ, ìµœê·¼ 4ë…„ê°„(2020~2023) í‰ê·  ì„±ì ì´ ê°€ì¥ ë†’ì€ í•™êµ ì´ë¦„ì„ ê³¼ëª©, í•™êµ í˜•íƒœë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df_melt = pd.melt(df, id_vars=['í•™êµ', 'ì—°ë„'], value_vars=['êµ­ì–´', 'ì˜ì–´', 'ìˆ˜í•™', 'ê³¼í•™'], var_name='ê³¼ëª©', value_name='ì ìˆ˜')<br>
df_melt = df_melt.groupby(['í•™êµ', 'ê³¼ëª©']).agg(ê³¼ëª©í‰ê· =('ì ìˆ˜', 'mean')).reset_index()<br>
answer = df_melt.sort_values(by=['ê³¼ëª©', 'ê³¼ëª©í‰ê· '], ascending=False).groupby('ê³¼ëª©').head(1)[['ê³¼ëª©', 'í•™êµ']].reset_index(drop=True)<br>
answer
	
<br><br>
|  ê³¼ëª©  |  í•™êµ  |
|:------:|:------:|
|  ì˜ì–´  | ì„œìš¸ê³  |
|  ìˆ˜í•™  | ë¶€ì‚°ê³  |
|  êµ­ì–´  | ê´‘ì£¼ê³  |
|  ê³¼í•™  | ê´‘ì£¼ê³  |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">9.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ë¡œ **ê°€ì¥ ë§ì´ ì†Œë¹„ëœ ì—ë„ˆì§€ì›(ì „ê¸°/ê°€ìŠ¤/ìˆ˜ë„)**ì„ êµ¬í•˜ê³ , ê·¸ ì—ë„ˆì§€ì›ë³„ë¡œ í•´ë‹¹ ì—°ë„ì—ì„œ ë°œìƒí•œ ì´ ìš”ê¸ˆì˜ í•©ê³„ë¥¼ êµ¬í•˜ì‹œì˜¤.
- ì´ ë•Œ, "ì‚¬ìš©ëŸ‰" ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë§ì´ ì†Œë¹„ëœ ì—ë„ˆì§€ì› ì„ ì •
- ì„ ì •ëœ ì—ë„ˆì§€ì›ì— ëŒ€í•´ â†’ í•´ë‹¹ ì—°ë„ "ìš”ê¸ˆ" ì´í•© êµ¬í•¨
- ì—°ë„ë³„ë¡œ ê²°ê³¼ëŠ” 1ê°œì”© ì¶œë ¥ (ì˜ˆì‹œ: ì—°ë„ / ì—ë„ˆì§€ì› / ì´ ìš”ê¸ˆ)
</h3>

<details>
<summary>ì½”ë“œ</summary>
melt = pd.melt(df, id_vars=['ì—°ë„', 'ì§€ì—­', 'êµ¬ë¶„'], value_vars=['ê°€ìŠ¤(mÂ³)', 'ìˆ˜ë„(mÂ³)', 'ì „ê¸°(kWh)'], var_name='ì—ë„ˆì§€ì›', value_name='ì´')<br><br>

melt1 = melt[melt['êµ¬ë¶„'] == 'ì‚¬ìš©ëŸ‰']<br>
melt2 = melt[melt['êµ¬ë¶„'] == 'ìš”ê¸ˆ']<br><br>

merge = pd.merge(melt1, melt2, on=['ì—°ë„', 'ì§€ì—­', 'ì—ë„ˆì§€ì›'], suffixes=['ì‚¬ìš©ëŸ‰', 'ìš”ê¸ˆ'])<br><br>

grouped = merge.groupby(['ì—°ë„', 'ì—ë„ˆì§€ì›'])[['ì´ì‚¬ìš©ëŸ‰', 'ì´ìš”ê¸ˆ']].sum().reset_index()<br>
target = grouped.groupby('ì—°ë„')['ì´ì‚¬ìš©ëŸ‰'].idxmax()<br>
answer = grouped.loc[target, ['ì—°ë„', 'ì—ë„ˆì§€ì›', 'ì´ìš”ê¸ˆ']]<br>
answer

<br><br>
| ì—°ë„ |  ì—ë„ˆì§€ì›  | ì´ìš”ê¸ˆ |
|:----:|:----------:|:------:|
| 2020 | ì „ê¸°(kWh)  |  3800  |
| 2021 | ì „ê¸°(kWh)  |  3500  |
| 2022 | ì „ê¸°(kWh)  |  3850  |
| 2023 | ì „ê¸°(kWh)  |  4000  |
</details>


<br><br><br><br>


<h3 style="font-weight:normal;">10.</h3>
<h3 style="font-weight:normal;">
ê° ê³ ê°IDë³„ë¡œ ë‹¤ìŒ ê·œì¹™ì„ ì ìš©í•˜ì—¬ ì›”ë³„ ì´ êµ¬ë§¤ê¸ˆì•¡ì„ ê³„ì‚°í•˜ê³ , ê·¸ ì¤‘ 2023ë…„ ì´ êµ¬ë§¤ê¸ˆì•¡ì´ ìƒìœ„ 10%ì— í•´ë‹¹í•˜ëŠ” ê³ ê°ë“¤ê³¼ ê³ ê° ìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
(ì´ ë•Œ, êµ¬ë§¤ê¸ˆì•¡ì´ ê²°ì¸¡ì¸ ê²½ìš°ì—ëŠ” ê°™ì€ ê³ ê°, ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ì—°ë„ë³„ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ìœ¼ë¡œ ì±„ìš¸ ê²ƒ (ë‹¨, í‰ê· ê°’ë„ ê²°ì¸¡ì´ë©´ ì „ì²´ ì¹´í…Œê³ ë¦¬ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ìœ¼ë¡œ ì±„ì›€))
</h3>

<details>
<summary>ì½”ë“œ</summary>
<span style="color:gray;"># êµ¬ë§¤ê¸ˆì•¡ì´ ê²°ì¸¡ì¹˜ì¸ í–‰ ëŒ€ì¹˜</span><br>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df.groupby(['ì—°ë„', 'ê³ ê°ID', 'ì¹´í…Œê³ ë¦¬'])['êµ¬ë§¤ê¸ˆì•¡'].transform('mean'))<br><br>

<span style="color:gray;"># í‰ê·  êµ¬ë§¤ê¸ˆì•¡ ê°’ë„ ê²°ì¸¡ì¹˜ì¸ í–‰ ëŒ€ì¹˜</span><br>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df['êµ¬ë§¤ê¸ˆì•¡'].mean())<br><br>

<span style="color:gray;"># ì›”ë³„ ì´ êµ¬ë§¤ê¸ˆì•¡ ë¨¼ì € êµ¬í•˜ê¸°</span><br>
monthly_sum = df.groupby(['ê³ ê°ID', 'ì—°ë„', 'ì›”'])['êµ¬ë§¤ê¸ˆì•¡'].sum().reset_index()<br><br>

<span style="color:gray;"># ë‹¤ì‹œ ì—°ë„ë³„ ì´ êµ¬ë§¤ê¸ˆì•¡ ê³„ì‚°</span><br>
grouped = monthly_sum.groupby(['ê³ ê°ID', 'ì—°ë„'])['êµ¬ë§¤ê¸ˆì•¡'].sum().reset_index()<br><br>

target = grouped[grouped['ì—°ë„'] == 2023]['êµ¬ë§¤ê¸ˆì•¡'].quantile(0.9)<br>
answer = grouped[(grouped['ì—°ë„'] == 2023) & (grouped['êµ¬ë§¤ê¸ˆì•¡'] >= target)]['ê³ ê°ID'].values.tolist()<br><br>

print("ì¡°ê±´ì— ë§ëŠ” ê³ ê°ë“¤:")<br>
for i in range(len(answer)):<br>
&nbsp;&nbsp;&nbsp;&nbsp;print(answer[i])<br><br>

print("\nì¡°ê±´ì— ë§ëŠ” ê³ ê° ìˆ˜:", len(answer))

<br><br>
>ì¡°ê±´ì— ë§ëŠ” ê³ ê°ë“¤:<br>
>CUST025<br>
>CUST028<br>
>CUST033<br>
>CUST061<br>
>CUST062<br>
>CUST065<br>
>CUST071<br>
>CUST077<br>
>CUST088<br>
>CUST095<br><br>
>
>ì¡°ê±´ì— ë§ëŠ” ê³ ê° ìˆ˜: 10
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">11-1.</h3>
<h3 style="font-weight:normal;">
ì—°ë ¹ëŒ€(20ëŒ€, 30ëŒ€, 40ëŒ€, 50ëŒ€, ...)ë¥¼ êµ¬ë¶„í•˜ëŠ” ì—°ë ¹ëŒ€ ì»¬ëŸ¼ì„ ë§Œë“¤ê³ , ê° ì—°ë ¹ëŒ€ë³„ë¡œ ì½œë ˆìŠ¤í…Œë¡¤ í‰ê· ì„ ê³„ì‚°í•˜ì‹œì˜¤. 
(ë‹¨, ì½œë ˆìŠ¤í…Œë¡¤ ê²°ì¸¡ì¹˜ëŠ” ê°™ì€ ì§€ì—­ ë‚´ ì—°ë ¹ëŒ€ í‰ê· ìœ¼ë¡œ ì±„ìš¸ ê²ƒ. (í‰ê· ê°’ë„ ê²°ì¸¡ì´ë©´ ì „ì²´ í‰ê· ìœ¼ë¡œ ì±„ì›€))
ìµœì¢… ì¶œë ¥ì€ ì—°ë ¹ëŒ€, í‰ê·  ì½œë ˆìŠ¤í…Œë¡¤ í˜•íƒœë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ì—°ë ¹ëŒ€'] = (df['ì—°ë ¹'] // 10 * 10).astype(str) + 'ëŒ€'<br><br>

<span style="color:gray;"># ì§€ì—­, ì—°ë ¹ëŒ€ ê¸°ì¤€ìœ¼ë¡œ ì½œë ˆìŠ¤í…Œë¡¤ ê° ê²°ì¸¡ì¹˜ ëŒ€ì¹˜</span><br>
df['ì½œë ˆìŠ¤í…Œë¡¤'] = df['ì½œë ˆìŠ¤í…Œë¡¤'].fillna(df.groupby(['ì—°ë ¹ëŒ€', 'ì§€ì—­'])['ì½œë ˆìŠ¤í…Œë¡¤'].transform('mean'))<br><br>

<span style="color:gray;"># ì•„ì§ë„ ê²°ì¸¡ì¹˜ì¸ ê°’ì€ ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì¹˜</span><br>
df['ì½œë ˆìŠ¤í…Œë¡¤'] = df['ì½œë ˆìŠ¤í…Œë¡¤'].fillna(df['ì½œë ˆìŠ¤í…Œë¡¤'].mean())<br><br>

answer = df.groupby('ì—°ë ¹ëŒ€')['ì½œë ˆìŠ¤í…Œë¡¤'].mean().reset_index()<br>
answer

<br><br>
| ì—°ë ¹ëŒ€ |  ì½œë ˆìŠ¤í…Œë¡¤  |
|:------:|:------------:|
|  20ëŒ€  | 196.598853   |
|  30ëŒ€  | 200.362484   |
|  40ëŒ€  | 196.960751   |
|  50ëŒ€  | 196.091550   |
|  60ëŒ€  | 197.436339   |
|  70ëŒ€  | 202.869849   |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">11-2.</h3>
<h3 style="font-weight:normal;">
í˜ˆì••, í˜ˆë‹¹, ì½œë ˆìŠ¤í…Œë¡¤ ì»¬ëŸ¼ì— ëŒ€í•´ **í‘œì¤€í™”(z-score standardization)**ë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì‹œì˜¤. (ì´ ë•Œ, í˜ˆë‹¹ì€ í˜ˆë‹¹ ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì¹˜)
í‘œì¤€í™”ëœ ì»¬ëŸ¼ëª…ì€ í˜ˆì••_zscore, í˜ˆë‹¹_zscore, ì½œë ˆìŠ¤í…Œë¡¤_zscoreë¡œ í•˜ì‹œì˜¤. ì´í›„ ì „ì²´ ë°ì´í„°ì—ì„œ í˜ˆì••_zscore > 1.5ë¥¼ ë§Œì¡±í•˜ëŠ” ë°ì´í„°ì˜ ìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
from scipy.stats import zscore<br><br>

df['í˜ˆë‹¹'] = df['í˜ˆë‹¹'].fillna(df['í˜ˆë‹¹'].mean())<br>
target_col = ['í˜ˆì••', 'í˜ˆë‹¹', 'ì½œë ˆìŠ¤í…Œë¡¤']<br>
change_col_name = ['í˜ˆì••_zscore', 'í˜ˆë‹¹_zscore', 'ì½œë ˆìŠ¤í…Œë¡¤_zscore']<br><br>

for new_col, col in zip(change_col_name, target_col):<br>
&nbsp;&nbsp;&nbsp;&nbsp;df[new_col] = zscore(df[col])<br><br>

answer = len(df[df['í˜ˆì••_zscore'] > 1.5])<br>
answer

<br><br>
>68
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">12-1.</h3>
<h3 style="font-weight:normal;">
ê° ì¹´í…Œê³ ë¦¬ë³„, ì„±ë³„ë¡œ í‰ê·  ì£¼ë¬¸ê¸ˆì•¡ì„ ê³„ì‚°í•˜ì‹œì˜¤. (ë‹¨, ì£¼ë¬¸ê¸ˆì•¡ ê²°ì¸¡ì¹˜ëŠ” ê°™ì€ ì¹´í…Œê³ ë¦¬, ì„±ë³„ ê·¸ë£¹ í‰ê· ìœ¼ë¡œ ì±„ìš´ í›„ ê³„ì‚°í•˜ê³ , í‰ê· ê°’ë„ ê²°ì¸¡ì´ë©´ ì „ì²´ í‰ê· ìœ¼ë¡œ ì±„ì›€)
ìµœì¢… ì¶œë ¥ì€ ì¹´í…Œê³ ë¦¬, ì„±ë³„, í‰ê·  ì£¼ë¬¸ê¸ˆì•¡ í˜•íƒœë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ì£¼ë¬¸ê¸ˆì•¡'] = df['ì£¼ë¬¸ê¸ˆì•¡'].fillna(df.groupby(['ì¹´í…Œê³ ë¦¬', 'ì„±ë³„'])['ì£¼ë¬¸ê¸ˆì•¡'].transform('mean'))<br>
df['ì£¼ë¬¸ê¸ˆì•¡'] = df['ì£¼ë¬¸ê¸ˆì•¡'].fillna(df['ì£¼ë¬¸ê¸ˆì•¡'].mean())<br><br>

answer = df.groupby(['ì¹´í…Œê³ ë¦¬', 'ì„±ë³„'])['ì£¼ë¬¸ê¸ˆì•¡'].mean().reset_index()<br>
display(answer)

<br><br>
| ì¹´í…Œê³ ë¦¬   | ì„±ë³„ |   ì£¼ë¬¸ê¸ˆì•¡    |
|:----------:|:---:|:-------------:|
| Books      |  F  |  98127.343750 |
| Books      |  M  | 102518.404762 |
| Clothing   |  F  | 101762.051429 |
| Clothing   |  M  |  94524.674419 |
| Electronics|  F  | 104034.844156 |
| Electronics|  M  |  94069.086957 |
| Home       |  F  | 109268.200000 |
| Home       |  M  | 104047.201439 |
| Toys       |  F  | 105476.724138 |
| Toys       |  M  |  98706.119403 |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">12-2.</h3>
<h3 style="font-weight:normal;">
êµ¬ë§¤ìˆ˜ëŸ‰ì— ëŒ€í•´ ìµœì†Œ-ìµœëŒ€ ì •ê·œí™”(min-max scaling) ë¥¼ ì ìš©í•˜ì—¬ êµ¬ë§¤ìˆ˜ëŸ‰_scaled ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì‹œì˜¤.
ì´í›„ êµ¬ë§¤ìˆ˜ëŸ‰_scaled >= 0.9 ë¥¼ ë§Œì¡±í•˜ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
from sklearn.preprocessing import MinMaxScaler<br><br>

minmax = MinMaxScaler()<br><br>

df['êµ¬ë§¤ìˆ˜ëŸ‰_scaled'] = minmax.fit_transform(df[['êµ¬ë§¤ìˆ˜ëŸ‰']])<br>
print(len(df[df['êµ¬ë§¤ìˆ˜ëŸ‰_scaled'] >= 0.9]))

<br><br>
>2
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">13-1.</h3>
<h3 style="font-weight:normal;">
ê° ê³ ê°IDë³„ë¡œ ë¶ˆë§Œì œê¸° ê²½í—˜ ì—¬ë¶€(ë¶ˆë§Œì œê¸° ì—¬ë¶€ê°€ í•œ ë²ˆì´ë¼ë„ 1ì¸ ê²½ìš° "Y", ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ "N")ë¥¼ ë‚˜íƒ€ë‚´ëŠ” íŒŒìƒ ì»¬ëŸ¼ì„ ìƒì„±í•˜ì‹œì˜¤.
ì´í›„ 2023ë…„ì— ë¶ˆë§Œì œê¸° ê²½í—˜ì´ "Y"ì¸ ê³ ê° ìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
target = df[df['ë¶ˆë§Œì œê¸°ì—¬ë¶€'] == 1].groupby("ê³ ê°ID")['ê³ ê°ID'].unique().index.tolist()<br>
df['ë¶ˆë§Œì œê¸°ê²½í—˜ì—¬ë¶€'] = df['ê³ ê°ID'].apply(lambda x: 'Y' if x in target else 'N')<br><br>

answer = df[(df['ì—°ë„'] == 2023) & (df['ë¶ˆë§Œì œê¸°ê²½í—˜ì—¬ë¶€'] == 'Y')]['ê³ ê°ID'].nunique()<br>
answer

<br><br>
>71
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">13-2.</h3>
<h3 style="font-weight:normal;">
ì—°ë ¹ëŒ€(10ëŒ€, 20ëŒ€, 30ëŒ€, 40ëŒ€, 50ëŒ€, 60ëŒ€ ì´ìƒ) ì»¬ëŸ¼ì„ ìƒì„±í•˜ê³ , ê° ì—°ë ¹ëŒ€ë³„ ì£¼ë¬¸ìˆ˜ëŸ‰ í‰ê· ê³¼ ì£¼ë¬¸ê¸ˆì•¡ í‰ê· ì„ êµ¬í•˜ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ì€ ì—°ë ¹ëŒ€, í‰ê·  ì£¼ë¬¸ìˆ˜ëŸ‰, í‰ê·  ì£¼ë¬¸ê¸ˆì•¡ í˜•íƒœë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ì—°ë ¹ëŒ€'] = df['ë‚˜ì´'].apply(lambda x: str(60) + 'ëŒ€ ì´ìƒ' if x >= 60 else str(x // 10 * 10) + 'ëŒ€')<br>
answer = df.groupby('ì—°ë ¹ëŒ€')[['ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì£¼ë¬¸ê¸ˆì•¡']].mean().reset_index()<br>
display(answer)
	
<br><br>
| ì—°ë ¹ëŒ€     | ì£¼ë¬¸ìˆ˜ëŸ‰  |   ì£¼ë¬¸ê¸ˆì•¡    |
|:---------:|:--------:|:-------------:|
| 10ëŒ€      | 1.985714 | 18390.685714  |
| 20ëŒ€      | 2.022923 | 20046.002865  |
| 30ëŒ€      | 2.086835 | 19513.540616  |
| 40ëŒ€      | 2.126582 | 20165.712025  |
| 50ëŒ€      | 1.953079 | 19724.384164  |
| 60ëŒ€ ì´ìƒ | 1.920981 | 20225.686649  |
</details>


<br><br><br><br>


<h3 style="font-weight:normal;">14-1.</h3>
<h3 style="font-weight:normal;">
ì—…ë¬´ë§Œì¡±ë„ê°€ ê²°ì¸¡ì¸ ì§ì›ì€ ë¶€ì„œë³„ í‰ê·  ì—…ë¬´ë§Œì¡±ë„ë¡œ ì±„ìš´ë‹¤. (ë‹¨, ë¶€ì„œë³„ í‰ê· ë„ ê²°ì¸¡ì´ë©´ ì „ì²´ í‰ê· ìœ¼ë¡œ ì±„ìš´ë‹¤)
ì´í›„, ê·¼ì†ì—°ìˆ˜ê°€ ê²°ì¸¡ì¸ ì§ì›ì€ ì œê±°í•œë‹¤.
ê·¸ ë‹¤ìŒ, ì—…ë¬´ë§Œì¡±ë„ì˜ ì‚¬ë¶„ìœ„ìˆ˜ ê¸°ì¤€ Q1 ì´í•˜ì¸ ì§ì› ì¤‘ ì„±ê³¼ë“±ê¸‰ì´ Aì¸ ì§ì› ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ì—…ë¬´ë§Œì¡±ë„'] = df['ì—…ë¬´ë§Œì¡±ë„'].fillna(df.groupby('ë¶€ì„œ')['ì—…ë¬´ë§Œì¡±ë„'].transform('mean'))<br>
df['ì—…ë¬´ë§Œì¡±ë„'] = df['ì—…ë¬´ë§Œì¡±ë„'].fillna(df['ì—…ë¬´ë§Œì¡±ë„'].mean())<br>
df1 = df[df['ê·¼ì†ì—°ìˆ˜'].notna()].copy()<br><br>

answer1 = len(df1[(df1['ì—…ë¬´ë§Œì¡±ë„'] <= df1['ì—…ë¬´ë§Œì¡±ë„'].quantile(0.25)) & (df1['ì„±ê³¼ë“±ê¸‰'] == 'A')])<br>
print(answer1)

<br><br>
>72
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">14-2.</h3>
<h3 style="font-weight:normal;">
ê·¼ì†ì—°ìˆ˜ê°€ 10ë…„ ì´ìƒì´ê³  êµìœ¡ì°¸ì—¬íšŸìˆ˜ê°€ ì „ì²´ í‰ê·  ì´ìƒì¸ ì§ì›ë“¤ì„ í•„í„°ë§í•œ í›„, í•´ë‹¹ ì§ì›ë“¤ì˜ ë¶€ì„œë³„ í‰ê·  ì—°ë´‰ì„ êµ¬í•˜ì‹œì˜¤.
ì´ë•Œ ì—°ë´‰ í‰ê· ì´ ì„¸ ë²ˆì§¸ë¡œ ë†’ì€ ë¶€ì„œì˜ í‰ê·  ì—°ë´‰ì„ ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df2 = df[(df['ê·¼ì†ì—°ìˆ˜'] >= 10.0) & (df['êµìœ¡ì°¸ì—¬íšŸìˆ˜'] >= df['êµìœ¡ì°¸ì—¬íšŸìˆ˜'].mean())].copy()<br>
answer2 = df2.groupby('ë¶€ì„œ')['ì—°ë´‰'].mean().sort_values(ascending=False).values[2]<br>
print(int(answer2))
	
<br><br>
>6476
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">14-3.</h3>
<h3 style="font-weight:normal;">
ê° ë¶€ì„œë³„ë¡œ ì—…ë¬´ë§Œì¡±ë„ ê¸°ì¤€ ìƒìœ„ 20% ì§ì›ë“¤ì˜ í‰ê·  ê·¼ì†ì—°ìˆ˜ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤. (ë‹¨, ì—…ë¬´ë§Œì¡±ë„ê°€ ê²°ì¸¡ì¸ ì§ì›ì€ ì œì™¸í•˜ë©°, ê·¼ì†ì—°ìˆ˜ê°€ ê²°ì¸¡ì¸ ì§ì›ë„ ì œì™¸í•œë‹¤)
ì´í›„ ê°€ì¥ í‰ê·  ê·¼ì†ì—°ìˆ˜ê°€ ë†’ì€ ë¶€ì„œëª…ì„ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df3 = df.dropna(subset=['ì—…ë¬´ë§Œì¡±ë„', 'ê·¼ì†ì—°ìˆ˜']).copy()<br>
target3 = df3.groupby('ë¶€ì„œ')['ì—…ë¬´ë§Œì¡±ë„'].transform(lambda x: x.quantile(0.8))<br>
df3_filtered = df3[df3['ì—…ë¬´ë§Œì¡±ë„'] >= target3]<br><br>

answer3 = df3_filtered.groupby('ë¶€ì„œ')['ê·¼ì†ì—°ìˆ˜'].mean().sort_values(ascending=False).index[0]<br>
print(answer3)

<br><br>
>Finance
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">15-1.</h3>
<h3 style="font-weight:normal;">
ê° ì œí’ˆêµ°ë³„ë¡œ ì—°ë„ì™€ ë¶„ê¸° ê¸°ì¤€ í‰ê·  ë°˜í’ˆë¥ (ë°˜í’ˆìˆ˜ëŸ‰ / íŒë§¤ìˆ˜ëŸ‰)ì„ êµ¬í•˜ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ì€ ì œí’ˆêµ°, ì—°ë„, ë¶„ê¸°, í‰ê·  ë°˜í’ˆë¥  ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df_grouped = df.groupby(['ì œí’ˆêµ°', 'ì—°ë„', 'ë¶„ê¸°'])[['íŒë§¤ìˆ˜ëŸ‰', 'ë°˜í’ˆìˆ˜ëŸ‰']].sum().reset_index()<br>
df_grouped['í‰ê· ë°˜í’ˆë¥ '] = df_grouped['ë°˜í’ˆìˆ˜ëŸ‰'] / df_grouped['íŒë§¤ìˆ˜ëŸ‰']<br><br>

answer1 = df_grouped[['ì œí’ˆêµ°', 'ì—°ë„', 'ë¶„ê¸°', 'í‰ê· ë°˜í’ˆë¥ ']]<br>
display(answer1)

<br><br>
| ì œí’ˆêµ° | ì—°ë„ | ë¶„ê¸° | í‰ê· ë°˜í’ˆë¥  |
|:-----:|:----:|:---:|:---------:|
| ê°€ì „  | 2022 | Q1  | 0.018182  |
| ê°€ì „  | 2022 | Q2  | 0.023077  |
| ê°€ì „  | 2023 | Q2  | 0.020000  |
| ê°€ì „  | 2023 | Q4  | 0.026316  |
| ì‹í’ˆ  | 2022 | Q3  | 0.020000  |
| ì‹í’ˆ  | 2023 | Q3  | 0.019048  |
| ì „ì  | 2022 | Q1  | 0.020833  |
| ì „ì  | 2022 | Q4  | 0.005556  |
| ì „ì  | 2023 | Q1  | 0.027273  |
| ì „ì  | 2023 | Q2  | 0.011765  |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">15-2.</h3>
<h3 style="font-weight:normal;">
ê° ì—°ë„ë³„ë¡œ ì§€ì—­ê³¼ ì œí’ˆêµ°ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¶œì•¡ ì´í•©ì„ ê³„ì‚°í•˜ê³ , ê°€ì¥ ë§¤ì¶œì´ ë†’ì€ ì§€ì—­-ì œí’ˆêµ° ì¡°í•©ì„ ì—°ë„ë³„ë¡œ 1ê°œì”© ì¶œë ¥í•˜ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ì€ ì—°ë„, ì§€ì—­, ì œí’ˆêµ°, ì´ ë§¤ì¶œì•¡ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df_grouped = df.groupby(['ì—°ë„', 'ì§€ì—­', 'ì œí’ˆêµ°'])['ë§¤ì¶œì•¡'].sum().reset_index()<br>
target3 = df_grouped.groupby('ì—°ë„')['ë§¤ì¶œì•¡'].transform(lambda x: x.max())<br>
answer3 = df_grouped.loc[df_grouped['ë§¤ì¶œì•¡'] == target3, ['ì—°ë„', 'ì§€ì—­', 'ì œí’ˆêµ°', 'ë§¤ì¶œì•¡']]<br>
answer3
	
<br><br>
| ì—°ë„ | ì§€ì—­ | ì œí’ˆêµ° |   ë§¤ì¶œì•¡   |
|:----:|:----:|:------:|:----------:|
| 2022 | ì„œìš¸ | ì „ì   | 23500000  |
| 2023 | ì„œìš¸ | ê°€ì „   | 17300000  |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">16.</h3>
<h3 style="font-weight:normal;">
ë‹¤ìŒì€ 2020~2023ë…„ê¹Œì§€ì˜ í•™êµë³„ ê³¼ëª©ë³„ í‰ê·  ì„±ì  ë°ì´í„°ì´ë‹¤.
ê° ê³¼ëª©ë³„ë¡œ 4ë…„ê°„ í‰ê·  ì„±ì ì´ ê°€ì¥ ë†’ì€ í•™êµëª…ì„ êµ¬í•˜ê³ , ìµœì¢… ì¶œë ¥ì€ ê³¼ëª©, í•™êµ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
melt = pd.melt(df, id_vars='í•™êµ', value_vars=['êµ­ì–´', 'ìˆ˜í•™', 'ì˜ì–´', 'ê³¼í•™'], var_name='ê³¼ëª©', value_name='ì ìˆ˜')<br>
grouped = melt.groupby(['í•™êµ', 'ê³¼ëª©'])['ì ìˆ˜'].mean().reset_index()<br>
target = grouped.groupby('ê³¼ëª©')['ì ìˆ˜'].idxmax()<br>
answer = grouped.loc[grouped.index.isin(target), ['ê³¼ëª©', 'í•™êµ']]<br>
answer
	
<br><br>
| ê³¼ëª© |              í•™êµ              |
|:----:|:-----------------------------:|
| ì˜ì–´ | Dawson, Ruiz and Aguirre      |
| ê³¼í•™ | Morris, Ross and Santana      |
| ìˆ˜í•™ | Parrish-Powell                |
| êµ­ì–´ | Pierce-Roman                  |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">17-1.</h3>
<h3 style="font-weight:normal;">
êµ¬ë§¤ê¸ˆì•¡ì´ ê²°ì¸¡ì¸ ê²½ìš°, ê°™ì€ ì„±ë³„Â·ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ì˜ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ìœ¼ë¡œ ì±„ìš°ê³ , í•´ë‹¹ ê·¸ë£¹ í‰ê· ë„ ê²°ì¸¡ì´ë©´ ì „ì²´ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ìœ¼ë¡œ ëŒ€ì²´í•˜ì‹œì˜¤.
ê·¸ í›„, ì—°ë ¹ëŒ€(10ëŒ€, 20ëŒ€, ..., 60ëŒ€ ì´ìƒ) ë¥¼ ë‚˜ëˆ„ê³ , ì—°ë ¹ëŒ€ë³„ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ê³¼ í‰ê·  ë¦¬ë·°ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ì€ ì—°ë ¹ëŒ€, í‰ê·  êµ¬ë§¤ê¸ˆì•¡, í‰ê·  ë¦¬ë·°ì ìˆ˜ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df.groupby(['ì„±ë³„', 'ì¹´í…Œê³ ë¦¬'])['êµ¬ë§¤ê¸ˆì•¡'].transform('mean'))<br>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df['êµ¬ë§¤ê¸ˆì•¡'].mean())<br><br>

df['ì—°ë ¹ëŒ€'] = df['ì—°ë ¹'].apply(lambda x: str(60) + 'ëŒ€ ì´ìƒ' if (x // 10 * 10) >= 60 else str(x // 10 * 10) + 'ëŒ€')<br>
answer1 = df.groupby('ì—°ë ¹ëŒ€')[['êµ¬ë§¤ê¸ˆì•¡', 'ë¦¬ë·°ì ìˆ˜']].agg({'êµ¬ë§¤ê¸ˆì•¡': 'mean', 'ë¦¬ë·°ì ìˆ˜': 'mean'}) \
.rename(columns={'êµ¬ë§¤ê¸ˆì•¡': 'í‰ê· êµ¬ë§¤ê¸ˆì•¡', 'ë¦¬ë·°ì ìˆ˜': 'í‰ê· ë¦¬ë·°ì ìˆ˜'}).reset_index()<br>
answer1

<br><br>
| ì—°ë ¹ëŒ€   |   í‰ê· êµ¬ë§¤ê¸ˆì•¡    | í‰ê· ë¦¬ë·°ì ìˆ˜ |
|:-------:|:----------------:|:------------:|
| 10ëŒ€    | 228403.518437    | 3.054167     |
| 20ëŒ€    | 245874.691944    | 2.957692     |
| 30ëŒ€    | 282802.035068    | 3.110390     |
| 40ëŒ€    | 220573.732107    | 2.876923     |
| 50ëŒ€    | 224191.891860    | 2.926263     |
| 60ëŒ€ ì´ìƒ | 231402.739518    | 2.947778     |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">17-2.</h3>
<h3 style="font-weight:normal;">
2023ë…„ì— í•œ ë²ˆì´ë¼ë„ ë¶ˆë§Œì œê¸°ë¥¼ í•œ ê³ ê°IDëŠ” â€˜ë¶ˆë§Œê²½í—˜ ìˆìŒâ€™, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° â€˜ë¶ˆë§Œê²½í—˜ ì—†ìŒâ€™ ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” íŒŒìƒ ì»¬ëŸ¼ì„ ë§Œë“¤ê³ ,
2023ë…„ ë¶ˆë§Œê²½í—˜ ìˆìŒ ê³ ê° ì¤‘ í‰ê·  êµ¬ë§¤ìˆ˜ëŸ‰ì´ ê°€ì¥ ë†’ì€ ì§€ì—­ì„ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df2 = df[df['ì—°ë„'] == 2023].copy()<br>
target2 = df2[df2['ë¶ˆë§Œì œê¸°'] != 0]['ê³ ê°ID'].unique()<br>
df['ë¶ˆë§Œê²½í—˜ì—¬ë¶€'] = df['ê³ ê°ID'].apply(lambda x: True if x in target2 else False)<br><br>

answer2 = df[df['ë¶ˆë§Œê²½í—˜ì—¬ë¶€'] == True].groupby('ì§€ì—­')['êµ¬ë§¤ìˆ˜ëŸ‰'].mean().idxmax()<br>
answer2

<br><br>
>'ì¸ì²œ'
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">18-1.</h3>
<h3 style="font-weight:normal;">
êµ¬ë§¤ê¸ˆì•¡ì´ ê²°ì¸¡ì¸ ê²½ìš° ì„±ë³„-ìƒí’ˆêµ° ê·¸ë£¹ í‰ê· ìœ¼ë¡œ ëŒ€ì²´, ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ì‹œì˜¤.
ì´í›„ ì—°ë ¹ëŒ€ë¥¼ 10ëŒ€ ë‹¨ìœ„ë¡œ êµ¬ë¶„ (20ëŒ€, 30ëŒ€, ..., 60ëŒ€ ì´ìƒ) í•˜ì—¬, ì—°ë ¹ëŒ€ë³„ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ê³¼ í‰ê·  ë¦¬ë·°ì ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ì€ ì—°ë ¹ëŒ€, í‰ê·  êµ¬ë§¤ê¸ˆì•¡, í‰ê·  ë¦¬ë·°ì ìˆ˜ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df.groupby(['ì„±ë³„', 'ìƒí’ˆêµ°'])['êµ¬ë§¤ê¸ˆì•¡'].transform('mean'))<br>
df['êµ¬ë§¤ê¸ˆì•¡'] = df['êµ¬ë§¤ê¸ˆì•¡'].fillna(df['êµ¬ë§¤ê¸ˆì•¡'].mean())<br><br>

df['ì—°ë ¹ëŒ€'] = df['ì—°ë ¹'].apply(lambda x: str(x // 10 * 10) + 'ëŒ€ ì´ìƒ' if x >= 60 else str(x // 10 * 10) + 'ëŒ€')<br>
answer1 = df.groupby('ì—°ë ¹ëŒ€')[['êµ¬ë§¤ê¸ˆì•¡', 'ë¦¬ë·°ì ìˆ˜']].mean().rename(columns={'êµ¬ë§¤ê¸ˆì•¡': 'í‰ê· êµ¬ë§¤ê¸ˆì•¡', 'ë¦¬ë·°ì ìˆ˜': 'í‰ê· ë¦¬ë·°ì ìˆ˜'}).reset_index()<br>
display(answer1)

<br><br>
| ì—°ë ¹ëŒ€   |   í‰ê· êµ¬ë§¤ê¸ˆì•¡    | í‰ê· ë¦¬ë·°ì ìˆ˜ |
|:-------:|:----------------:|:------------:|
| 20ëŒ€    | 57024.448168     | 3.146341     |
| 30ëŒ€    | 59161.923237     | 3.230088     |
| 40ëŒ€    | 53897.458934     | 3.152542     |
| 50ëŒ€    | 53794.968391     | 3.186992     |
| 60ëŒ€ ì´ìƒ | 50942.592508     | 3.133333     |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">18-2.</h3>
<h3 style="font-weight:normal;">
ê° ê³ ê°IDë³„ë¡œ í•œ ë²ˆì´ë¼ë„ ë°˜í’ˆí•œ ì´ë ¥ì´ ìˆìœ¼ë©´ 'Y', ì—†ìœ¼ë©´ 'N' ìœ¼ë¡œ ìƒˆë¡œìš´ íŒŒìƒë³€ìˆ˜ë¥¼ ìƒì„±í•˜ì‹œì˜¤.
ê·¸ í›„, 2023ë…„ ê°€ì…ì ì¤‘ 'Y'ë¡œ ë¶„ë¥˜ëœ ê³ ê°ì˜ ìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ê°€ì…ë…„ë„'] = df['ê°€ì…ì¼'].str.extract(r'(\d\d\d\d)-')<br>
target = df[df['ë°˜í’ˆì—¬ë¶€'] == 1]['ê³ ê°ID'].unique().tolist()<br>
df['ë°˜í’ˆì´ë ¥'] = df['ê³ ê°ID'].apply(lambda x: 'Y' if x in target else 'N')<br><br>

answer2 = df[(df['ê°€ì…ë…„ë„'] == '2023') & (df['ë°˜í’ˆì´ë ¥'] == 'Y')]['ê³ ê°ID'].nunique()<br>
print(answer2)

<br><br>
>32
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">18-3.</h3>
<h3 style="font-weight:normal;">
ìƒí’ˆêµ°ë³„ë¡œ ë¦¬ë·°ì ìˆ˜ê°€ 4ì  ì´ìƒì¸ ë°ì´í„°ë§Œ í•„í„°ë§í•œ í›„, ë¦¬ë·°ì ìˆ˜ í‰ê· ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆêµ° ì´ë¦„ì„ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ë¦¬ë·°ì ìˆ˜'] = df['ë¦¬ë·°ì ìˆ˜'].fillna(df['ë¦¬ë·°ì ìˆ˜'].mode()[0])<br>
target = df[df['ë¦¬ë·°ì ìˆ˜'] >= 4.0][['ìƒí’ˆêµ°', 'ë¦¬ë·°ì ìˆ˜']]<br>
answer3 = target.groupby('ìƒí’ˆêµ°')['ë¦¬ë·°ì ìˆ˜'].mean().idxmax()<br>
answer3
	
<br><br>
>'ë„ì„œ'
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">19-1.</h3>
<h3 style="font-weight:normal;">
ë°°ì†¡ë§Œì¡±ë„ê°€ ê²°ì¸¡ì¸ ê²½ìš°ì—ëŠ” ë™ì¼ ê²°ì œë°©ì‹ ê·¸ë£¹ì˜ ë°°ì†¡ë§Œì¡±ë„ í‰ê· ìœ¼ë¡œ ì±„ìš°ê³ , ì—¬ì „íˆ ê²°ì¸¡ì¸ ê²½ìš° ì „ì²´ í‰ê· ìœ¼ë¡œ ì±„ìš´ í›„,
ë‹¤ìŒê³¼ ê°™ì€ ê¸°ì¤€ìœ¼ë¡œ ë°°ì†¡ë§Œì¡±ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒÂ·ì¤‘Â·í•˜ ë“±ê¸‰ì„ ë¶€ì—¬í•˜ì‹œì˜¤.	
	4 ì´ìƒ: ìƒ
	3 ì´ìƒ 4 ë¯¸ë§Œ: ì¤‘
	3 ë¯¸ë§Œ: í•˜

ì´í›„, ë“±ê¸‰ë³„ë¡œ ì „ì²´ í‰ê·  êµ¬ë§¤ê¸ˆì•¡ì„ êµ¬í•˜ê³  ë‘ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ í…Œì´ë¸”ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['ë°°ì†¡ë§Œì¡±ë„'] = df['ë°°ì†¡ë§Œì¡±ë„'].fillna(df.groupby('ê²°ì œë°©ì‹')['ë°°ì†¡ë§Œì¡±ë„'].transform('mean'))<br>
df['ë°°ì†¡ë§Œì¡±ë„'] = df['ë°°ì†¡ë§Œì¡±ë„'].fillna(df['ë°°ì†¡ë§Œì¡±ë„'].mean())<br>
df['ë“±ê¸‰'] = df['ë°°ì†¡ë§Œì¡±ë„'].apply(lambda x: 'ìƒ' if x >= 4.0 else ('ì¤‘' if x >= 3.0 else 'í•˜'))<br><br>

answer1 = df.groupby('ë“±ê¸‰')['êµ¬ë§¤ê¸ˆì•¡'].mean().reset_index().rename(columns={'êµ¬ë§¤ê¸ˆì•¡': 'í‰ê· êµ¬ë§¤ê¸ˆì•¡'})<br>
answer1

<br><br>
| ë“±ê¸‰ |   í‰ê· êµ¬ë§¤ê¸ˆì•¡   |
|:---:|:---------------:|
| ìƒ  | 154022.003984   |
| ì¤‘  | 152182.707692   |
| í•˜  | 154345.755020   |
</details>


<br><br><br><br>

<h3 style="font-weight:normal;">19-2.</h3>
<h3 style="font-weight:normal;">
ê° ê³ ê°IDë³„ë¡œ ë¦¬ë·°ë¥¼ í•œ ìƒí’ˆ ë¹„ìœ¨ì„ ê³„ì‚°í•˜ì‹œì˜¤. (ë¦¬ë·°ì‘ì„±=1 ì´ë©´ ë¦¬ë·°í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼)
ì´í›„ ë¦¬ë·° ë¹„ìœ¨ì´ 70% ì´ìƒì¸ ê³ ê°IDì˜ ìˆ˜ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
<span style="color:gray;"># ë°©ë²• 1: </span><br>
cdf = pd.crosstab(df['ê³ ê°ID'], df['ë¦¬ë·°ì‘ì„±'], dropna=False).fillna(0)<br>
cdf['ë¦¬ë·°ë¹„ìœ¨'] = cdf[1] / (cdf[0] + cdf[1])<br>
answer1 = len(cdf[cdf['ë¦¬ë·°ë¹„ìœ¨'] >= 0.7])<br>
print("ê³ ê° ìˆ˜:", answer1)<br><br>

<span style="color:gray;"># ë°©ë²• 2: </span><br>
review_stats = df.groupby('ê³ ê°ID')['ë¦¬ë·°ì‘ì„±'].agg(['sum', 'count']).reset_index()<br>
review_stats['ë¦¬ë·°ë¹„ìœ¨'] = review_stats['sum'] / review_stats['count']<br>
answer2 = len(review_stats[review_stats['ë¦¬ë·°ë¹„ìœ¨'] >= 0.7])<br>
print("ê³ ê° ìˆ˜:", answer2)<br><br>

<span style="color:gray;"># ë°©ë²• 3: </span><br>
pivot = df.pivot_table(index='ê³ ê°ID', values='ë¦¬ë·°ì‘ì„±', aggfunc=['sum', 'count']).reset_index()<br>
pivot.columns = ['ê³ ê°ID', 'sum', 'count']<br>
pivot['ë¦¬ë·°ë¹„ìœ¨'] = pivot['sum'] / pivot['count']<br>
answer3 = len(pivot[pivot['ë¦¬ë·°ë¹„ìœ¨'] >= 0.7])<br>
print("ê³ ê° ìˆ˜:", answer3)

<br><br>
>ê³ ê° ìˆ˜: 47
</details>

<br><br><br><br>

<h3 style="font-weight:normal;">19-3.</h3>
<h3 style="font-weight:normal;">
2023ë…„ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬, ê° ê²°ì œë°©ì‹ë³„ë¡œ ë°˜í’ˆìœ¨(ë°˜í’ˆì—¬ë¶€ê°€ 1ì¸ ë¹„ìœ¨) ì„ êµ¬í•˜ê³ , ë°˜í’ˆìœ¨ì´ ê°€ì¥ ë†’ì€ ê²°ì œë°©ì‹ëª…ì„ ì¶œë ¥í•˜ì‹œì˜¤.
</h3>

<details>
<summary>ì½”ë“œ</summary>
df['êµ¬ë§¤ì¼'] = pd.to_datetime(df['êµ¬ë§¤ì¼'])<br>
df['êµ¬ë§¤ë…„ë„'] = df['êµ¬ë§¤ì¼'].dt.year<br><br>

df_filtered = df[df['êµ¬ë§¤ë…„ë„'] == 2023]<br>
grouped = df_filtered.groupby('ê²°ì œë°©ì‹')['ë°˜í’ˆì—¬ë¶€'].agg(['sum', 'count'])<br>
grouped['ë°˜í’ˆë¹„ìœ¨'] = grouped['sum'] / grouped['count']<br>
answer3 = grouped.sort_values(by='ë°˜í’ˆë¹„ìœ¨', ascending=False).index[0]<br>
answer3

<br><br>
>'í¬ì¸íŠ¸'
</details>

</details>




# ğŸ“ 2ìœ í˜•

<details>
<summary><h2>ğŸ“Œ ë¬¸ì œ ëª©ë¡ ë³´ê¸°</h2></summary>
<h2 style="font-weight:normal;">íšŒê·€</h2>
<h3 style="font-weight:normal;">1.</h3> 
<h3 style="font-weight:normal;">1. í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: salary, í‰ê°€ ì§€í‘œ: RMSE)</h3>

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_employee.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_employee.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.ensemble import RandomForestRegressor<br>
from sklearn.metrics import mean_squared_error<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br>
<span style="color:gray;"># print(train.isna().sum())</span><br><br>

<span style="color:gray;"># ë°ì´í„° ë¶„í• </span><br>
train_X = train.drop(columns='salary', axis=1)<br>
train_y = train['salary']<br>
test_X = test<br><br>

<span style="color:gray;"># test ID ì¶”ì¶œ</span><br>
test_ID = test_X['ID']<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID', 'name']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í• </span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X[num_columns], test_X_encoder], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ íšŒê·€ëª¨í˜• í•™ìŠµ</span><br>
rf = RandomForestRegressor(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
train_predict = rf.predict(train_X_preprocessed)<br>
valid_predict = rf.predict(valid_X_preprocessed)<br><br>

<span style="color:gray;"># ì„±ëŠ¥ í‰ê°€</span><br>
train_rmse = np.sqrt(mean_squared_error(train_y, train_predict))<br>
valid_rmse = np.sqrt(mean_squared_error(valid_y, valid_predict))<br><br>

print("train RMSE:", round(train_rmse, 3))<br>
print("valid RMSE:", round(valid_rmse, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred = rf.predict(test_X_preprocessed)<br>
result = pd.DataFrame({'ID': test_ID, 'pred': test_pred})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>

<h3 style="font-weight:normal;">2.</h3> 
<h3 style="font-weight:normal;">í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: price, í‰ê°€ ì§€í‘œ: RMSE)</h3>

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_apartment.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_apartment.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.impute import SimpleImputer<br>
from sklearn.ensemble import RandomForestRegressor<br>
from sklearn.metrics import mean_squared_error<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br>
<span style="color:gray;"># print(train.isna().sum())</span><br><br>

<span style="color:gray;"># ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬</span><br>
train_X = train.drop(columns='price', axis=1)<br>
train_y = train['price']<br>
test_X = test.copy()<br><br>

<span style="color:gray;"># test ID ì¶”ì¶œ</span><br>
test_ID = test_X['ID']<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í• </span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)<br><br>

<span style="color:gray;"># ê²°ì¸¡ê°’ í‰ê·  ëŒ€ì¹˜</span><br>
imputer = SimpleImputer(strategy='mean')<br><br>

train_X[num_columns] = imputer.fit_transform(train_X[num_columns])<br>
valid_X[num_columns] = imputer.transform(valid_X[num_columns])<br>
test_X[num_columns] = imputer.transform(test_X[num_columns])<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X_encoder, test_X[num_columns]], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ íšŒê·€ëª¨í˜• í•™ìŠµ</span><br>
rf = RandomForestRegressor(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
train_predict = rf.predict(train_X_preprocessed)<br>
valid_predict = rf.predict(valid_X_preprocessed)<br><br>

<span style="color:gray;"># ì„±ëŠ¥ í‰ê°€</span><br>
train_rmse = np.sqrt(mean_squared_error(train_y, train_predict))<br>
valid_rmse = np.sqrt(mean_squared_error(valid_y, valid_predict))<br><br>

print("train RMSE:", round(train_rmse, 3))<br>
print("valid RMSE:", round(valid_rmse, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred = rf.predict(test_X_preprocessed)<br>
result = pd.DataFrame({'ID': test_ID, 'pred': test_pred})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>


<h3 style="font-weight:normal;">3.</h3> 
<h3 style="font-weight:normal;">í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: mpg, í‰ê°€ ì§€í‘œ: MAE) (ê²°ì¸¡ê°’ì€ 0ìœ¼ë¡œ ë‚˜íƒ€ëƒ„) </h3>

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_fuel.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_fuel.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.ensemble import RandomForestRegressor<br>
from sklearn.metrics import mean_absolute_error<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br><br>

<span style="color:gray;"># ê²°ì¸¡ì¹˜ ìˆëŠ” ì¹¼ëŸ¼ í™•ì¸</span><br>
cols_with_zero = [col for col in train.columns if (train[col] == 0).any()]<br>
print(cols_with_zero)<br><br>

<span style="color:gray;"># ê²°ì¸¡ê°’ ëŒ€ì¹˜</span><br>
for col in cols_with_zero:<br>
&nbsp;&nbsp;&nbsp;&nbsp;train[col] = train[col].apply(lambda x: train[col].median() if x == 0 else x)<br>
&nbsp;&nbsp;&nbsp;&nbsp;test[col] = test[col].apply(lambda x: test[col].median() if x == 0 else x)<br><br>

<span style="color:gray;"># ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬</span><br>
train_X = train.drop(columns='mpg', axis=1)<br>
train_y = train['mpg']<br>
test_X = test.copy()<br><br>

<span style="color:gray;"># test ID ì¶”ì¶œ</span><br>
test_ID = test_X['ID']<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í• </span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X_encoder, test_X[num_columns]], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ íšŒê·€ëª¨í˜• í•™ìŠµ</span><br>
rf = RandomForestRegressor(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
train_predict = rf.predict(train_X_preprocessed)<br>
valid_predict = rf.predict(valid_X_preprocessed)<br><br>

<span style="color:gray;"># ì„±ëŠ¥ í‰ê°€</span><br>
train_rmse = mean_absolute_error(train_y, train_predict)<br>
valid_rmse = mean_absolute_error(valid_y, valid_predict)<br><br>

print("train RMSE:", round(train_rmse, 3))<br>
print("valid RMSE:", round(valid_rmse, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred = rf.predict(test_X_preprocessed)<br>
result = pd.DataFrame({'ID': test_ID, 'pred': test_pred})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>

<h2 style="font-weight:normal;">ë¶„ë¥˜</h2>
<h3 style="font-weight:normal;">1.</h3> 
<h3 style="font-weight:normal;">í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: churn, í‰ê°€ ì§€í‘œ: AUC)</h3> 

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_customer.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_customer.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.ensemble import RandomForestClassifier<br>
from sklearn.metrics import roc_auc_score<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br>
<span style="color:gray;"># print(train['churn'].value_counts(), "\n")</span><br><br>

<span style="color:gray;"># ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬</span><br>
train_X = train.drop(columns='churn', axis=1)<br>
train_y = train['churn']<br>
test_X = test.copy()<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í• </span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X_encoder, test_X[num_columns]], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ëª¨ë¸ í•™ìŠµ</span><br>
rf = RandomForestClassifier(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
valid_pred_proba = rf.predict_proba(valid_X_preprocessed)[:, 1]<br><br>

<span style="color:gray;"># AUC í‰ê°€</span><br>
auc = roc_auc_score(valid_y, valid_pred_proba)<br>
print("Validation AUC:", round(auc, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred = rf.predict(test_X_preprocessed)<br>
result = pd.DataFrame({'ID': test['ID'], 'pred': test_pred})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>


<h3 style="font-weight:normal;">2.</h3> 
<h3 style="font-weight:normal;">í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: default, í‰ê°€ ì§€í‘œ: f1_score)</h3> 

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_credit.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_credit.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.ensemble import RandomForestClassifier<br>
from sklearn.metrics import f1_score<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br>
<span style="color:gray;"># print(train.isna().sum())</span><br>
<span style="color:gray;"># print(train['default'].value_counts(), "\n")</span><br><br>

<span style="color:gray;"># default ê·¸ë£¹ë³„ë¡œ ê²°ì¸¡ê°’ ëŒ€ì¹˜</span><br>
means = train.groupby('default')['credit_score'].mean()<br>
train['credit_score'] = train.apply(lambda x: means[x['default']] if pd.isna(x['credit_score']) else x['credit_score'], axis=1)<br><br>

<span style="color:gray;"># ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬</span><br>
train_X = train.drop(columns='default', axis=1)<br>
train_y = train['default']<br>
test_X = test.copy()<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í• </span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X_encoder, test_X[num_columns]], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ëª¨ë¸ í•™ìŠµ</span><br>
rf = RandomForestClassifier(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
valid_pred = rf.predict(valid_X_preprocessed)<br><br>

<span style="color:gray;"># F1-score í‰ê°€</span><br>
f1 = f1_score(valid_y, valid_pred, average='macro')<br>
print("Validation F1-score:", round(f1, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred_proba = rf.predict_proba(test_X_preprocessed)[:, 1]<br>
result = pd.DataFrame({'ID': test['ID'], 'pred_proba': test_pred_proba})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>

<h3 style="font-weight:normal;">3.</h3> 
<h3 style="font-weight:normal;">í›ˆë ¨ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ì‹œì˜¤. (Target: satisfaction, í‰ê°€ ì§€í‘œ: recall)<br>
ê·¸ë¦¬ê³  í‰ê°€ ì§€í‘œ ì ìˆ˜ê°€ 0.95 ì´ìƒì´ ë‚˜ì˜¤ê²Œ ëª¨ë¸ì„ í•™ìŠµí•˜ì‹œì˜¤.</h3> 

train = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/train_satisfaction.csv")<br>
test = pd.read_csv("https://raw.githubusercontent.com/pigbbong/bigdata-exam-practice/main/type2/test_satisfaction.csv")

<details>
<summary>ì½”ë“œ</summary>
import pandas as pd<br>
import numpy as np<br>
from sklearn.model_selection import train_test_split<br>
from sklearn.preprocessing import OneHotEncoder<br>
from sklearn.ensemble import RandomForestClassifier<br>
from sklearn.metrics import recall_score<br><br>

<span style="color:gray;"># ë°ì´í„° í™•ì¸</span><br>
<span style="color:gray;"># print(train.head(), "\n")</span><br>
<span style="color:gray;"># print(train.info())</span><br>
<span style="color:gray;"># print(train.isna().sum())</span><br>
<span style="color:gray;"># print(train['satisfaction'].value_counts(), "\n")</span><br><br>

<span style="color:gray;"># ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ë¶„ë¦¬</span><br>
train_X = train.drop(columns='satisfaction', axis=1)<br>
train_y = train['satisfaction']<br>
test_X = test.copy()<br><br>

<span style="color:gray;"># í•„ìš” ì—†ëŠ” ì¹¼ëŸ¼ ì œê±°</span><br>
drop_col = ['ID']<br>
train_X = train_X.drop(columns=drop_col)<br><br>

<span style="color:gray;"># ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë³€ìˆ˜ êµ¬ë¶„</span><br>
num_columns = train_X.select_dtypes('number').columns.tolist()<br>
cat_columns = train_X.select_dtypes('object').columns.tolist()<br><br>

<span style="color:gray;"># ê²€ì¦ìš© ë°ì´í„° ë¶„í•  (ì¸µí™” ì ìš©)</span><br>
train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)<br><br>

<span style="color:gray;"># ì›-í•« ì¸ì½”ë”©</span><br>
onehotencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')<br><br>

train_X_encoder = onehotencoder.fit_transform(train_X[cat_columns])<br>
valid_X_encoder = onehotencoder.transform(valid_X[cat_columns])<br>
test_X_encoder = onehotencoder.transform(test_X[cat_columns])<br><br>

<span style="color:gray;"># ë°ì´í„° ê²°í•©</span><br>
train_X_preprocessed = np.concatenate([train_X_encoder, train_X[num_columns]], axis=1)<br>
valid_X_preprocessed = np.concatenate([valid_X_encoder, valid_X[num_columns]], axis=1)<br>
test_X_preprocessed = np.concatenate([test_X_encoder, test_X[num_columns]], axis=1)<br><br>

<span style="color:gray;"># ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ëª¨ë¸ í•™ìŠµ</span><br>
rf = RandomForestClassifier(random_state=42)<br>
rf.fit(train_X_preprocessed, train_y)<br><br>

<span style="color:gray;"># ì˜ˆì¸¡</span><br>
valid_pred = rf.predict(valid_X_preprocessed)<br><br>

<span style="color:gray;"># Recall í‰ê°€</span><br>
recall = recall_score(valid_y, valid_pred, average='macro')<br>
print("Recall:", round(recall, 3))<br><br>

<span style="color:gray;"># í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±</span><br>
test_pred = rf.predict(test_X_preprocessed)<br>
result = pd.DataFrame({'ID': test['ID'], 'pred': test_pred})<br>
result.to_csv('result.csv', index=False)<br>
print(result.head())<br>
</details>

</details>









# ğŸ“ 3ìœ í˜•

<details>
<summary><h2>ğŸ“Œ ë¬¸ì œ ëª©ë¡ ë³´ê¸°</h2></summary>


<h3 style="font-weight:normal;">1-1.</h3>  
<h3 style="font-weight:normal;">  
ì—°ë ¹ëŒ€ë³„ë¡œ ì§ˆë³‘ìœ ë¬´ì™€ì˜ ë…ë¦½ì„± ì—¬ë¶€ë¥¼ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ê²€ì • ë°©ë²•ì„ ì„ íƒí•˜ì—¬ ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • ê²°ê³¼ë¥¼ í•´ì„í•˜ì‹œì˜¤. (ìœ ì˜ìˆ˜ì¤€ì€ 0.05ë¡œ ê°€ì •í•œë‹¤)  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chi2_contingency<br><br>
cdf = pd.crosstab(df['ì—°ë ¹ëŒ€'], df['ì§ˆë³‘ìœ ë¬´'])<br>
chi2_stats, p, _, _ = chi2_contingency(cdf)<br>
print("ê²€ì •í†µê³„ëŸ‰:", chi2_stats)<br>
print("p_values:", p)<br><br>
if p < 0.05:<br>
	&nbsp;&nbsp;&nbsp;&nbsp;print("ê·€ë¬´ê°€ì„¤ ê¸°ê°")<br>
else:<br>
	&nbsp;&nbsp;&nbsp;&nbsp;print("ê·€ë¬´ê°€ì„¤ ì±„íƒ")

<br><br>

> ê²€ì •í†µê³„ëŸ‰: 24.71328589749828<br>
> p_values: 1.7725414243948196e-05<br>
> ê·€ë¬´ê°€ì„¤ ê¸°ê°
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">1-2.</h3>  
<h3 style="font-weight:normal;">  
ì—°ë ¹ëŒ€, ì„±ë³„, êµìœ¡ìˆ˜ì¤€ì„ ë…ë¦½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê³  ë‹¤ì¤‘íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ê³ ,  
<br>  
ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜ì™€ R-squared ê°’ì„ êµ¬í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import ols<br><br>
model = ols("ì§ˆë³‘ìœ ë¬´ ~ C(ì—°ë ¹ëŒ€) + C(ì„±ë³„) + C(êµìœ¡ìˆ˜ì¤€)", data=df).fit()<br><br>
pvalues = model.pvalues[1:]<br><br>
print(f"ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜: {len(pvalues[pvalues < 0.05])}ê°œ")<br>
print("R-squared:", model.rsquared)

<br><br>
> ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜: 2ê°œ<br>
> R-squared: 0.09380851372083054
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">2-1.</h3>  
<h3 style="font-weight:normal;">  
ì§ì—…êµ°ì— ë”°ë¼ ë§Œì„±ì§ˆí™˜ìœ ë¬´ì™€ì˜ ë…ë¦½ì„± ì—¬ë¶€ë¥¼ ê²€ì •í•˜ê³ ,  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • ê²°ê³¼ë¥¼ í•´ì„í•˜ì‹œì˜¤. (ìœ ì˜ìˆ˜ì¤€ì€ 0.05ë¡œ ê°€ì •í•œë‹¤)  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chi2_contingency<br><br>
cdf = pd.crosstab(df['ì§ì—…êµ°'], df['ë§Œì„±ì§ˆí™˜ìœ ë¬´'])<br>
chi2_stats, p, ddof, expected = chi2_contingency(cdf)<br><br>
if p < 0.05:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì§ì—…êµ°ì— ë”°ë¥¸ ë§Œì„±ì§ˆí™˜ìœ ë¬´ëŠ” ì„œë¡œ ì—°ê´€ë˜ì–´ìˆìŒ")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì§ì—…êµ°ì— ë”°ë¼ ë§Œì„±ì§ˆí™˜ìœ ë¬´ëŠ” ì„œë¡œ ê´€ê³„ê°€ ì—†ìŒ")

<br><br>
> ì§ì—…êµ°ì— ë”°ë¥¸ ë§Œì„±ì§ˆí™˜ìœ ë¬´ëŠ” ì„œë¡œ ì—°ê´€ë˜ì–´ìˆìŒ
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">2-2.</h3>  
<h3 style="font-weight:normal;">  
ìˆ˜ë©´ì‹œê°„ì„ ì¢…ì†ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê³  ì§ì—…êµ°, ê²°í˜¼ì—¬ë¶€, ìš´ë™ë¹ˆë„, ìŠ¤íŠ¸ë ˆìŠ¤ìˆ˜ì¤€ì„ ë…ë¦½ë³€ìˆ˜ë¡œ ì„¤ì •í•œ ë‹¤ì¤‘íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤.  
<br>  
ê·¸ë¦¬ê³  ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜ë¥¼ êµ¬í•˜ê³ , R-squared ê°’ì„ êµ¬í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import ols<br><br>
model = ols("ìˆ˜ë©´ì‹œê°„ ~ C(ì§ì—…êµ°) + C(ê²°í˜¼ì—¬ë¶€) + C(ìš´ë™ë¹ˆë„) + ìŠ¤íŠ¸ë ˆìŠ¤ìˆ˜ì¤€", data=df).fit()<br><br>
pvalues = model.pvalues[1:]<br><br>
print(f"ëª¨ë¸ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜: {len(list(pvalues[pvalues < 0.05]))}ê°œ\n")<br>
print("R-squared:", model.rsquared)

<br><br>
> ëª¨ë¸ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ì˜ ê°œìˆ˜: 0ê°œ<br>
> R-squared: 0.01919543404363533
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">2-3.</h3>  
<h3 style="font-weight:normal;">  
ë§Œì„±ì§ˆí™˜ìœ ë¬´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤. (ì§ì—…êµ°, ê²°í˜¼ì—¬ë¶€, ìš´ë™ë¹ˆë„, ìˆ˜ë©´ì‹œê°„, ìŠ¤íŠ¸ë ˆìŠ¤ìˆ˜ì¤€ì„ ë…ë¦½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì‹œì˜¤.)  
<br>  
ê·¸ë¦¬ê³  ëª¨í˜•ì˜ ì „ë°˜ì  ìœ ì˜ì„± ê²€ì •ì„ ìœ„í•´ LR ê²€ì •(Likelihood Ratio Test) ê²°ê³¼ë¥¼ ì œì‹œí•˜ê³ , í†µê³„ì  ìœ ì˜ì„±ì„ í‰ê°€í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import logit<br><br>
model = logit("ë§Œì„±ì§ˆí™˜ìœ ë¬´ ~ C(ì§ì—…êµ°) + C(ê²°í˜¼ì—¬ë¶€) + C(ìš´ë™ë¹ˆë„) + ìŠ¤íŠ¸ë ˆìŠ¤ìˆ˜ì¤€", data=df).fit()<br><br>
print("LR Test Statistics:", -2 * (model.llnull - model.llf))<br>
print("LR Test p-value:", model.llr_pvalue)

<br><br>
> LR Test Statistics: 44.45408393664076<br>
> LR Test p-value: 4.669023162177591e-07
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">3-1.</h3>  
<h3 style="font-weight:normal;">  
ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ì„ ë¶„ì„í•˜ëŠ” íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤. (ë…ë¦½ë³€ìˆ˜: ì§€ì—­, í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„, ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„)  
<br>  
ê·¸ë¦¬ê³  ë‹¤ìŒ ê°’ì„ ì¶œë ¥í•˜ì‹œì˜¤:  
</h3>  

<h4 style="font-weight:normal;">- íšŒê·€ê³„ìˆ˜(Î²) ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- p-value ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜</h4>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import ols<br><br>
model = ols("ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„ ~ C(ì§€ì—­) + í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„ + ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„", data=df).fit()<br><br>
coef = model.params[1:]<br>
pvalues = model.pvalues[1:]<br><br>
print("íšŒê·€ê³„ìˆ˜ ê°’:")<br>
print(coef)<br>
print("\n")<br>
print("p-values:")<br>
print(pvalues)<br>
print("\n")<br>
print("ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜:")<br>
print(len(pvalues[pvalues < 0.05]))

<br><br>

>íšŒê·€ê³„ìˆ˜ ê°’: <br>
>C(ì§€ì—­)[T.ê´‘ì£¼]   -0.002578 <br>
>C(ì§€ì—­)[T.ëŒ€êµ¬]   -0.203613 <br>
>C(ì§€ì—­)[T.ë¶€ì‚°]   -0.085643 <br>
>C(ì§€ì—­)[T.ì„œìš¸]   -0.083842 <br>
>í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„    -0.026694 <br>
>ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.042047 <br><br>

>p-values: <br>
>C(ì§€ì—­)[T.ê´‘ì£¼]    0.989130 <br>
>C(ì§€ì—­)[T.ëŒ€êµ¬]    0.273061 <br>
>C(ì§€ì—­)[T.ë¶€ì‚°]    0.646854 <br>
>C(ì§€ì—­)[T.ì„œìš¸]    0.668706 <br>
>í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.651553 <br>
>ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.331137 <br><br>

>ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜: 0 <br>
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">3-2.</h3>  
<h3 style="font-weight:normal;">  
ì†Œì…œë¯¸ë””ì–´ì´ìš© ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤. (ë…ë¦½ë³€ìˆ˜: ì§€ì—­, í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„, ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„, ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„)  
<br>  
ê·¸ë¦¬ê³  ë‹¤ìŒ ê°’ì„ ì¶œë ¥í•˜ì‹œì˜¤:  
</h3>  

<h4 style="font-weight:normal;">- íšŒê·€ê³„ìˆ˜(Î²) ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- p-value ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜</h4>  
<h4 style="font-weight:normal;">- ê° ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„(odds ratio) ê°’ ì „ì²´ (exp(Î²)ë¡œ ê³„ì‚°)</h4>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import logit<br>
import numpy as np<br><br>
model = logit("ì†Œì…œë¯¸ë””ì–´ì´ìš© ~ C(ì§€ì—­) + í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„ + ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„ + ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„", data=df).fit()<br><br>
coef = model.params[1:]<br>
pvalues = model.pvalues[1:]<br><br>
print("íšŒê·€ê³„ìˆ˜ ê°’:")<br>
print(coef)<br>
print("\n")<br>
print("p-values:")<br>
print(pvalues)<br>
print("\n")<br>
print("ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜:")<br>
print(len(pvalues[pvalues < 0.05]))<br>
print("\n")<br>
print("ì˜¤ì¦ˆë¹„:")<br>
print(np.exp(model.params[1:]))

<br><br>
>íšŒê·€ê³„ìˆ˜ ê°’: <br>
>C(ì§€ì—­)[T.ê´‘ì£¼]   -0.159362 <br>
>C(ì§€ì—­)[T.ëŒ€êµ¬]    0.082727 <br>
>C(ì§€ì—­)[T.ë¶€ì‚°]    0.239479 <br>
>C(ì§€ì—­)[T.ì„œìš¸]   -0.716144 <br>
>í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.042339 <br>
>ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.333166 <br>
>ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„       0.486477 <br><br>



>p-values: <br>
>C(ì§€ì—­)[T.ê´‘ì£¼]    0.671304 <br>
>C(ì§€ì—­)[T.ëŒ€êµ¬]    0.820795 <br>
>C(ì§€ì—­)[T.ë¶€ì‚°]    0.509214 <br>
>C(ì§€ì—­)[T.ì„œìš¸]    0.089156 <br>
>í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.723037 <br>
>ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     0.000183 <br>
>ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„       0.000006 <br><br>



>ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜: 2 <br><br>


>ì˜¤ì¦ˆë¹„: <br>
>C(ì§€ì—­)[T.ê´‘ì£¼]    0.852688 <br>
>C(ì§€ì—­)[T.ëŒ€êµ¬]    1.086245 <br>
>C(ì§€ì—­)[T.ë¶€ì‚°]    1.270587 <br>
>C(ì§€ì—­)[T.ì„œìš¸]    0.488633 <br>
>í‰ì¼_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     1.043248 <br>
>ì£¼ë§_ì¸í„°ë„·ì‚¬ìš©ì‹œê°„     1.395379 <br>
>ìŠ¤ë§ˆíŠ¸í°ì‚¬ìš©ì‹œê°„       1.626576 

</details>  

<br><br><br><br>



<h3 style="font-weight:normal;">4-1.</h3>  
<h3 style="font-weight:normal;">  
ì„±ë³„ì— ë”°ë¥¸ í‰ê·  ì²´ì¤‘ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  

from scipy.stats import shapiro, levene, ttest_ind, mannwhitneyu<br><br>
male = df[df['ì„±ë³„'] == 'ë‚¨']['ì²´ì¤‘'].reset_index(drop=True)<br>
female = df[df['ì„±ë³„'] == 'ì—¬']['ì²´ì¤‘'].reset_index(drop=True)<br><br>
male_stat, male_p = shapiro(male)<br>
female_stat, female_p = shapiro(female)<br><br>
if (male_p >= 0.05) & (female_p >= 0.05):<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì´ ì •ê·œì„±ì„ ë§Œì¡±í•¨")<br><br>
    &nbsp;&nbsp;&nbsp;&nbsp;l_stat, l_p = levene(male, female)<br><br>
    &nbsp;&nbsp;&nbsp;&nbsp;if l_p >= 0.05:<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì˜ ë“±ë¶„ì‚°ì„±ì´ ë§Œì¡±ë˜ë¯€ë¡œ ë…ë¦½ t-ê²€ì •ì„ ì‹œí–‰í•¨")<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t_stat, t_p = ttest_ind(male, female)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("ê²€ì •í†µê³„ëŸ‰:", t_stat)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("pvalues:", t_p)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;else:<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì´ ë“±ë¶„ì‚°ì„±ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Welch's t-ê²€ì •ì¼ ì‹œí–‰í•¨")<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;t_stat, t_p = ttest_ind(male, female, equal_var=False)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("ê²€ì •í†µê³„ëŸ‰:", t_stat)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print("pvalues:", t_p)<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ ì¤‘ ì •ê·œì„±ì„ ë§Œì¡±í•˜ì§€ ì•Šì€ ì§‘ë‹¨ì´ ìˆìœ¼ë¯€ë¡œ ë¹„ëª¨ìˆ˜ ê²€ì •ì„ ì‹œí–‰í•¨")<br>
    &nbsp;&nbsp;&nbsp;&nbsp;u_stat, u_p = mannwhitneyu(male, female)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ê²€ì •í†µê³„ëŸ‰:", u_stat)<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("pvalues:", u_p)

<br><br>

> ë‘ ì§‘ë‹¨ì´ ì •ê·œì„±ì„ ë§Œì¡±í•¨<br>
> ë‘ ì§‘ë‹¨ì˜ ë“±ë¶„ì‚°ì„±ì´ ë§Œì¡±ë˜ë¯€ë¡œ ë…ë¦½ t-ê²€ì •ì„ ì‹œí–‰í•¨<br>
> ê²€ì •í†µê³„ëŸ‰: 1.208913892570682<br>
> pvalues: 0.227654240467682
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">4-2.</h3>  
<h3 style="font-weight:normal;">  
í¡ì—°ì—¬ë¶€ì™€ ìš´ë™ì—¬ë¶€ê°€ ë…ë¦½ì ì¸ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chi2_contingency<br><br>
cdf = pd.crosstab(df['í¡ì—°ì—¬ë¶€'], df['ìš´ë™ì—¬ë¶€'])<br>
chi2_stats, chi2_p, ddof, expected = chi2_contingency(cdf)<br>
print("Statistics:", chi2_stats)<br>
print("p-values:", chi2_p)

<br><br>
>Statistics: 3.052418082722308<br>
>p-values: 0.08061703166032919
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">5-1.</h3>  
<h3 style="font-weight:normal;">  
í•™ë ¥ìˆ˜ì¤€ì— ë”°ë¼ ì§ë¬´ë§Œì¡±ë„ì˜ í‰ê· ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro, levene, f_oneway<br><br>
for group in df['í•™ë ¥ìˆ˜ì¤€'].unique():<br>
    stat, p = shapiro(df[df['í•™ë ¥ìˆ˜ì¤€'] == group]['ì§ë¬´ë§Œì¡±ë„'])<br>
    print(f"[{group}] ì •ê·œì„±ê²€ì • p-value: {p}")<br><br>

groups = [df[df['í•™ë ¥ìˆ˜ì¤€'] == g]['ì§ë¬´ë§Œì¡±ë„'] for g in df['í•™ë ¥ìˆ˜ì¤€'].unique()]<br>
stat, p = levene(*groups)<br>
print("ë“±ë¶„ì‚°ì„± ê²€ì • p-value:", p)<br><br>
stat, p = f_oneway(*groups)<br>
print("ANOVA stats:", stat)<br>
print("ANOVA p-value:", p)

<br><br>
>[ê³ ì¡¸] ì •ê·œì„±ê²€ì • p-value: 0.28955228892252133<br>
>[ëŒ€í•™ì›ì¡¸] ì •ê·œì„±ê²€ì • p-value: 0.6482530202159127<br>
>[ëŒ€ì¡¸] ì •ê·œì„±ê²€ì • p-value: 0.10586676249673443<br>
>ë“±ë¶„ì‚°ì„± ê²€ì • p-value: 0.35191382138446<br>
>ANOVA stats: 0.17646311829870298<br>
>ANOVA p-value: 0.8383048677370049
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">5-2.</h3>  
<h3 style="font-weight:normal;">  
ì¬íƒê·¼ë¬´ ì—¬ë¶€ì™€ ì´ì§ ê²½í—˜ ì—¬ë¶€ê°€ ë…ë¦½ì ì¸ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chi2_contingency<br><br>
cdf = pd.crosstab(df['ì¬íƒê·¼ë¬´ì—¬ë¶€'], df['ì´ì§ê²½í—˜ì—¬ë¶€'])<br>
chi2_stats, p, ddof, expected = chi2_contingency(cdf)<br><br>
print("chi2_stats:", chi2_stats)<br>
print("p-value:", p)

<br><br>
>chi2_stats: 0.0<br>
>p-value: 1.0<br>
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">5-3.</h3>  
<h3 style="font-weight:normal;">  
ì£¼ë‹¹ê·¼ë¬´ì‹œê°„ì´ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro<br><br>
stat, p = shapiro(df['ì£¼ë‹¹ê·¼ë¬´ì‹œê°„'])<br>
print("statictis:", stat)<br>
print("p-value:", p)<br><br>
if p < 0.05:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì •ê·œì„± ë¶ˆë§Œì¡±")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì •ê·œì„± ë§Œì¡±")

<br><br>
>statictis: 0.9935192674208136<br>
>p-value: 0.13854889195838865
>ì •ê·œì„± ë§Œì¡±
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">6-1.</h3>  
<h3 style="font-weight:normal;">  
ì—…ë¬´ì„±ê³¼ ì ìˆ˜ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê³ , ë…ë¦½ë³€ìˆ˜ë¡œ ë¶€ì„œ, ì§ê¸‰, ê·¼ì†ì—°ìˆ˜, ì£¼ë‹¹ê·¼ë¬´ì‹œê°„ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¤‘íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤.  
<br>  
ê·¸ë¦¬ê³  ë‹¤ìŒ ê°’ë“¤ì„ ì¶œë ¥í•˜ì‹œì˜¤:  
</h3>  

<h4 style="font-weight:normal;">- íšŒê·€ê³„ìˆ˜(Î²) ê°’ ì „ì²´ ì¶œë ¥</h4>  
<h4 style="font-weight:normal;">- p-value ê°’ ì „ì²´ ì¶œë ¥</h4>  
<h4 style="font-weight:normal;">- ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜ ì¶œë ¥ (ìœ ì˜ ìˆ˜ì¤€ì€ 0.05ë¡œ ì„¤ì •)</h4>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import ols<br><br>
model = ols("ì—…ë¬´ì„±ê³¼ì ìˆ˜ ~ C(ë¶€ì„œ) + C(ì§ê¸‰) + ê·¼ì†ì—°ìˆ˜ + ì£¼ë‹¹ê·¼ë¬´ì‹œê°„", data=df).fit()<br><br>
print("íšŒê·€ê³„ìˆ˜ ê°’:")<br>
print(model.params[1:])<br>
print("\n")<br>
print("p-value ê°’:")<br>
print(model.pvalues[1:])<br>
print("\n")<br>
pvalues = model.pvalues[1:]<br>
significant_pvalue = len(pvalues[pvalues < 0.05])<br>
print("ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ ê°œìˆ˜:", significant_pvalue)

<br><br>
>íšŒê·€ê³„ìˆ˜ ê°’:<br>
>C(ë¶€ì„œ)[T.ì˜ì—…]    3.860968<br>
>C(ë¶€ì„œ)[T.ì¸ì‚¬]   -0.487387<br>
>C(ë¶€ì„œ)[T.ì¬ë¬´]    0.215100<br>
>C(ì§ê¸‰)[T.ëŒ€ë¦¬]   -4.393583<br>
>C(ì§ê¸‰)[T.ë¶€ì¥]    3.177155<br>
>C(ì§ê¸‰)[T.ì‚¬ì›]   -3.560375<br>
>C(ì§ê¸‰)[T.ì°¨ì¥]    1.359326<br>
>ê·¼ì†ì—°ìˆ˜           1.402535<br>
>ì£¼ë‹¹ê·¼ë¬´ì‹œê°„         0.824601<br><br>


>p-value ê°’:<br>
>C(ë¶€ì„œ)[T.ì˜ì—…]    1.453251e-07<br>
>C(ë¶€ì„œ)[T.ì¸ì‚¬]    5.003544e-01<br>
>C(ë¶€ì„œ)[T.ì¬ë¬´]    7.583646e-01<br>
>C(ì§ê¸‰)[T.ëŒ€ë¦¬]    2.328691e-08<br>
>C(ì§ê¸‰)[T.ë¶€ì¥]    1.061265e-04<br>
>C(ì§ê¸‰)[T.ì‚¬ì›]    1.146126e-05<br>
>C(ì§ê¸‰)[T.ì°¨ì¥]    8.517250e-02<br>
>ê·¼ì†ì—°ìˆ˜           8.578075e-44<br>
>ì£¼ë‹¹ê·¼ë¬´ì‹œê°„         1.005734e-45<br><br>


>ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ ê°œìˆ˜: 6
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">6-2.</h3>  
<h3 style="font-weight:normal;">  
ìœ„ì—ì„œ êµ¬ì¶•í•œ OLS íšŒê·€ëª¨í˜•ì˜ ì”ì°¨(residuals)ê°€ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro<br><br>
residuals = model.resid<br>
stat, p = shapiro(residuals)<br><br>
if p < 0.05:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì •ê·œë¶„í¬ ë¶ˆë§Œì¡±")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì •ê·œë¶„í¬ ë§Œì¡±")<br><br>
print("statistics:", stat)<br>
print("p-value:", p)

<br><br>
>ì •ê·œë¶„í¬ ë§Œì¡±<br>
>statistics: 0.9974856994141608<br>
>p-value: 0.809330150039685
</details>  

<br><br><br><br>



<h3 style="font-weight:normal;">7.</h3>  
<h3 style="font-weight:normal;">  
ë‘ ì‹ì´ìš”ë²• ê·¸ë£¹ ê°„ ê³µë³µ í˜ˆë‹¹ì˜ í‰ê·  ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œì§€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•œ ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ ,  
<br>  
ê·¸ë•Œì˜ ê²€ì •í†µê³„ëŸ‰ ê°’ì„ êµ¬í•˜ì—¬ë¼.  
<br>  
(ë‹¨, ì–‘ì¸¡ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ì‹ ë¢°ìˆ˜ì¤€ì€ 95%ë¡œ í•˜ë©°, ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•  ê²ƒ)  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro, levene, mannwhitneyu, ttest_ind<br><br>
group1 = df[df['DietGroup'] == 'A']['Glucose']<br>
group2 = df[df['DietGroup'] == 'B']['Glucose']<br><br>
<span style="color:gray;"># ì •ê·œì„± ê²€ì •</span><br>
stat1, p1 = shapiro(group1)<br>
stat2, p2 = shapiro(group2)<br><br>
if p1 >= 0.05 and p2 >= 0.05:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì˜ ì •ê·œì„±ì´ ë§Œì¡±ë¨")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ì •ê·œì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠëŠ” ì§‘ë‹¨ì´ ìˆìŒ")<br><br>
<span style="color:gray;"># ë“±ë¶„ì‚°ì„± ê²€ì •</span><br>
l_stat, l_p = levene(group1, group2)<br><br>
if l_p >= 0.05:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì˜ ë“±ë¶„ì‚°ì„±ì„ ì´ë£¨ê³  ìˆìŒ")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("ë‘ ì§‘ë‹¨ì´ ë“±ë¶„ì‚°ì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŒ")<br><br>
<span style="color:gray;"># ë…ë¦½í‘œë³¸ t-ê²€ì • ì‹œí–‰</span><br>
t_stat, t_p = ttest_ind(group2, group1)<br><br>
print(t_stat.round(3))

<br><br>
>ë‘ ì§‘ë‹¨ì˜ ì •ê·œì„±ì´ ë§Œì¡±ë¨<br>
>ë‘ ì§‘ë‹¨ì˜ ë“±ë¶„ì‚°ì„±ì„ ì´ë£¨ê³  ìˆìŒ<br>
>3.981
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">8.</h3>  
<h3 style="font-weight:normal;">  
ì„¸ ê°€ì§€ ë§ˆì¼€íŒ… ì „ëµ ê°„ ê³ ê° ì§€ì¶œ ê¸ˆì•¡ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ë¥¼ ê²€ì •í•˜ê³ ,  
<br>  
ê·¸ë•Œì˜ ë¶„ì‚°ë¶„ì„ F-í†µê³„ëŸ‰ ê°’ì„ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤.  
<br>  
(ì‹ ë¢°ìˆ˜ì¤€ 95%, ì–‘ì¸¡ ê²€ì •)  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import f_oneway<br><br>
group1 = df[df['Strategy'] == 'A']['Spending']<br>
group2 = df[df['Strategy'] == 'B']['Spending']<br>
group3 = df[df['Strategy'] == 'C']['Spending']<br><br>
f_stats, f_p = f_oneway(group1, group2, group3)<br>
print("F-í†µê³„ëŸ‰:", f_stats.round(3))<br>
print("pvalue:", f_p.round(3))

<br><br>
>F-í†µê³„ëŸ‰: 10.938<br>
>pvalue: 0.0
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">9.</h3>  
<h3 style="font-weight:normal;">  
ë§ˆì¼€íŒ… ì „ëµ, ì—°ë ¹ëŒ€, ê·¸ë¦¬ê³  ì´ë“¤ì˜ ìƒí˜¸ì‘ìš© íš¨ê³¼ê°€ ê³ ê° ì§€ì¶œ ê¸ˆì•¡ì— ìœ ì˜í•œ ì˜í–¥ì„ ì£¼ëŠ”ì§€ë¥¼ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ê° ìš”ì¸ì˜ ë¶„ì‚°ë¶„ì„ F-í†µê³„ëŸ‰ ê°’ì„ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
import statsmodels.api as sm<br>
from statsmodels.formula.api import ols<br><br>
<span style="color:gray;"># ìƒí˜¸ì‘ìš© í¬í•¨ ëª¨ë¸</span><br>
model = ols("Spending ~ C(Strategy) * C(AgeGroup)", data=df).fit()<br><br>
<span style="color:gray;"># ë¶„ì‚°ë¶„ì„ í…Œì´ë¸”</span><br>
anova = sm.stats.anova_lm(model, typ=2)<br><br>
<span style="color:gray;"># F-í†µê³„ëŸ‰ ì¶”ì¶œ ë° ì¶œë ¥</span><br>
print("C(Strategy) statistics:", anova.loc['C(Strategy)', 'F'].round(3))<br>
print("C(AgeGroup) statistics:", anova.loc['C(AgeGroup)', 'F'].round(3))<br>
print("Interaction statistics:", anova.loc['C(Strategy):C(AgeGroup)', 'F'].round(3))

<br><br>
>C(Strategy) statistics: 14.629<br>
>C(AgeGroup) statistics: 2.19<br>
>Interaction statistics: 1.914
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">10-1.</h3>  
<h3 style="font-weight:normal;">  
ì‹ ì•½ ì²˜ì¹˜ ê·¸ë£¹(Treatment)ì— ë”°ë¼ í˜ˆì••(BloodPressure)ì˜ ë¶„ì‚°ì´ ë‹¬ë¼ì§€ëŠ”ì§€ íŒë‹¨í•˜ê³ ì í•œë‹¤.  
<br>  
Control, DrugA, DrugB ê·¸ë£¹ ì¤‘ ë‘ ê·¸ë£¹ì„ ì„ íƒí•˜ì—¬ ë¶„ì‚°ì´ í° ìª½ì„ ë¶„ìë¡œ í•˜ëŠ” F-ê²€ì •ì„ ìˆ˜í–‰í•˜ì‹œì˜¤.  
<br>  
ê·¸ë¦¬ê³  F-ê²€ì • í†µê³„ëŸ‰ì„ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>
<summary>ì½”ë“œ</summary>

```python
import numpy as np
from scipy.stats import f

group1 = df[df['Treatment'] == 'Control']['BloodPressure']
group2 = df[df['Treatment'] == 'DrugA']['BloodPressure']
group3 = df[df['Treatment'] == 'DrugB']['BloodPressure']

group2_var = np.var(group2, ddof=1)
group3_var = np.var(group3, ddof=1)

n2 = len(group2)
n3 = len(group3)

if group2_var > group3_var:
    f_stats = group2_var / group3_var
    df2 = n2 - 1
    df3 = n3 - 1
    pvalue = f.sf(f_stats, df2, df3)
else:
    f_stats = group3_var / group2_var
    df2 = n2 - 1
    df3 = n3 - 1
    pvalue = f.sf(f_stats, df3, df2)

print("F_statistics:", f_stats.round(3))
print("p-value:", pvalue.round(3))
```

>F_statistics: 1.946<br>
>p-value: 0.012
</details>  



<br><br><br><br>


<h3 style="font-weight:normal;">10-2.</h3>  
<h3 style="font-weight:normal;">  
ì„±ë³„(Gender)ì— ë”°ë¥¸ í˜ˆë‹¹(Glucose) ë¶„ì‚°ì´ ë™ì¼í•œì§€ ê²€ì •í•˜ê³ ,  
<br>  
F-ê²€ì • í†µê³„ëŸ‰ì„ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤. (ë¶„ì‚°ì´ ë” í° ìª½ì„ ë¶„ìë¡œ ì‚¬ìš©í•  ê²ƒ)  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
import numpy as np<br>
from scipy.stats import f<br><br>
group1 = df[df['Gender'] == 'Male']['Glucose']<br>
group2 = df[df['Gender'] == 'Female']['Glucose']<br><br>
group1_var = np.var(group1, ddof=1)<br>
group2_var = np.var(group2, ddof=1)<br><br>
n1 = len(group1)<br>
n2 = len(group2)<br><br>
df1 = n1 - 1<br>
df2 = n2 - 1<br><br>
if group1_var > group2_var:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;f_stats = group1_var / group2_var<br>
    &nbsp;&nbsp;&nbsp;&nbsp;pvalue = f.sf(f_stats, df1, df2)<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;f_stats = group2_var / group1_var<br>
    &nbsp;&nbsp;&nbsp;&nbsp;pvalue = f.sf(f_stats, df2, df1)<br><br>
print("F-statistics:", f_stats.round(3))<br>
print("pvalue:", pvalue.round(3))<br><br>
<span style="color:gray;"># í•©ë™ ë¶„ì‚°ëŸ‰ ê³„ì‚°</span><br>
pooled_var = ((n1 - 1) * group1_var + (n2 - 1) * group2_var) / (n1 + n2 - 2)<br><br>
print("í•©ë™ ë¶„ì‚°ëŸ‰ (Pooled Variance):", round(pooled_var, 3))

<br><br>
>F-statistics: 1.666<br>
>pvalue: 0.014<br>
>í•©ë™ ë¶„ì‚°ëŸ‰ (Pooled Variance): 214.932
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">10-3.</h3>  
<h3 style="font-weight:normal;">  
DrugB ê·¸ë£¹ì˜ í˜ˆì••(BloodPressure) ë¶„ì‚°ì´ Control ë˜ëŠ” DrugAë³´ë‹¤ í†µê³„ì ìœ¼ë¡œ ë” í°ì§€ë¥¼ ë³´ê¸° ìœ„í•´,  
<br>  
DrugB-Control, DrugB-DrugA ë‘ ìŒì— ëŒ€í•´ ê°ê° F-ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ ,  
<br>  
ê°ê°ì˜ F-ê²€ì • í†µê³„ëŸ‰ì„ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
import numpy as np<br><br>
group1 = df[df['Treatment'] == 'DrugB']['BloodPressure']<br>
group2 = df[df['Treatment'] == 'DrugA']['BloodPressure']<br>
group3 = df[df['Treatment'] == 'Control']['BloodPressure']<br><br>
group1_var = np.var(group1, ddof=1)<br>
group2_var = np.var(group2, ddof=1)<br>
group3_var = np.var(group3, ddof=1)<br><br>
print("DrugBì™€ DrugAì˜ Fê²€ì •í†µê³„ëŸ‰:", (group1_var / group2_var).round(3))<br><br>
if group1_var / group2_var > 1.0:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("DrugBì˜ ê²€ì •í†µê³„ëŸ‰ì´ DrugAë³´ë‹¤ í¬ë‹¤.", end='\n\n')<br>
else:<br>
    p&nbsp;&nbsp;&nbsp;&nbsp;rint("DrugBì˜ ë¶„ì‚°ì´ DrugAë³´ë‹¤ ì‘ë‹¤.", end='\n\n')<br><br>
print("DrugBì™€ Controlì˜ Fê²€ì •í†µê³„ëŸ‰:", (group1_var / group3_var).round(3))<br><br>
if group1_var / group3_var > 1.0:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("DrugBì˜ ê²€ì •í†µê³„ëŸ‰ì´ Controlë³´ë‹¤ í¬ë‹¤.")<br>
else:<br>
    &nbsp;&nbsp;&nbsp;&nbsp;print("DrugBì˜ ë¶„ì‚°ì´ Controlë³´ë‹¤ ì‘ë‹¤.")<br>

<br><br>
>DrugBì™€ DrugAì˜ Fê²€ì •í†µê³„ëŸ‰: 1.946<br>
>DrugBì˜ ê²€ì •í†µê³„ëŸ‰ì´ DrugAë³´ë‹¤ í¬ë‹¤.<br><br>
>
>DrugBì™€ Controlì˜ Fê²€ì •í†µê³„ëŸ‰: 2.986<br>
>DrugBì˜ ê²€ì •í†µê³„ëŸ‰ì´ Controlë³´ë‹¤ í¬ë‹¤.
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">11-1.</h3>  
<h3 style="font-weight:normal;">  
ì„±ë³„ì— ë”°ë¼ í‚¤ì˜ í‰ê· ì— ì°¨ì´ê°€ ìˆëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro, levene, ttest_ind<br><br>
male = df[df['ì„±ë³„'] == 'ë‚¨']['í‚¤']<br>
female = df[df['ì„±ë³„'] == 'ì—¬']['í‚¤']<br><br>
<span style="color:gray;"># print(shapiro(male))</span><br>
<span style="color:gray;"># print(shapiro(female))</span><br>
<span style="color:gray;"># -> ë‘ ì§‘ë‹¨ ëª¨ë‘ ì •ê·œì„±ì„ ë§Œì¡±í•œë‹¤.</span><br><br>
<span style="color:gray;"># print(levene(male, female))</span><br>
<span style="color:gray;"># -> ë‘ ì§‘ë‹¨ì˜ ë“±ë¶„ì‚°ì„±ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ welch's t-ê²€ì •ì„ ì‹œí–‰í•œë‹¤.</span><br><br>
stats, p = ttest_ind(male, female, equal_var=False)<br><br>
print("statistics:", stats)<br>
print("pvalue:", p)

<br><br>
>statistics: -0.17549603962612095<br>
>pvalue: 0.8607868693135134
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">11-2.</h3>  
<h3 style="font-weight:normal;">  
í¡ì—° ì—¬ë¶€ì™€ ìš´ë™ ì—¬ë¶€ê°€ ì„œë¡œ ë…ë¦½ì ì¸ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chi2_contingency<br><br>
cdf = pd.crosstab(df['í¡ì—°ì—¬ë¶€'], df['ìš´ë™ì—¬ë¶€'])<br>
chi2_stats, chi2_p, _ , _ = chi2_contingency(cdf)<br>
print("statistics:", chi2_stats)<br>
print("pvalues:", chi2_p)<br>
</details>  

<br><br>
>statistics: 2.1122034295222973<br>
>pvalues: 0.14612877750522046

<br><br><br><br>



<h3 style="font-weight:normal;">11-3.</h3>  
<h3 style="font-weight:normal;">  
í˜ˆì••ì´ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ì„ íƒí•˜ì—¬ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import shapiro<br><br>
blpr = df['í˜ˆì••']<br>
stat, p = shapiro(blpr)<br>
print("statistics:", stat)<br>
print("pvalues:", p)<br>

<br><br>
>statistics: 0.9935618194246021<br>
>pvalues: 0.0866211621977162
</details>



<br><br><br><br>


<h3 style="font-weight:normal;">11-4.</h3>  
<h3 style="font-weight:normal;">  
ì—°ë ¹ëŒ€ì— ë”°ë¼ ì²´ì¤‘ì˜ ë¶„ì‚°ì´ ë™ì¼í•œì§€ ê²€ì •í•˜ì‹œì˜¤.  
<br>  
ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import levene<br><br>
<span style="color:gray;"># ê° ê·¸ë£¹ë³„ ì²´ì¤‘ ë°ì´í„° ì¶”ì¶œ</span><br>
group_20 = df[df['ì—°ë ¹ëŒ€'] == '20ëŒ€']['ì²´ì¤‘']<br>
group_30 = df[df['ì—°ë ¹ëŒ€'] == '30ëŒ€']['ì²´ì¤‘']<br>
group_40 = df[df['ì—°ë ¹ëŒ€'] == '40ëŒ€']['ì²´ì¤‘']<br>
group_50 = df[df['ì—°ë ¹ëŒ€'] == '50ëŒ€']['ì²´ì¤‘']<br><br>
<span style="color:gray;"># Levene ë“±ë¶„ì‚°ì„± ê²€ì • ìˆ˜í–‰</span><br>
stat, p = levene(group_20, group_30, group_40, group_50)<br><br>
print("Levene statistics:", stat)<br>
print("p-value:", p)

<br><br>
>Levene statistics: 2.524537878254589<br>
>p-value: 0.057262483899653514
</details>  


<br><br><br><br>


<h3 style="font-weight:normal;">11-5.</h3>  
<h3 style="font-weight:normal;">  
ì´ ë°ì´í„°ì…‹ì—ì„œ ì—°ë ¹ëŒ€ ë³€ìˆ˜ì˜ ë¶„í¬ê°€ ë‹¤ìŒ ì´ë¡ ì  ë¶„í¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì •í•˜ì‹œì˜¤.  
</h3>  
<br>  
ê¸°ëŒ€ ì´ë¡ ì  ë¶„í¬ (ë¹„ìœ¨ ê¸°ì¤€):  
<h4 style="font-weight:normal;">- 20ëŒ€: 20%</h4>  
<h4 style="font-weight:normal;">- 30ëŒ€: 30%</h4>  
<h4 style="font-weight:normal;">- 40ëŒ€: 30%</h4>  
<h4 style="font-weight:normal;">- 50ëŒ€: 20%</h4>  
<br>  
<h3 style="font-weight:normal;">  
ì ì ˆí•œ ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , ê²€ì • í†µê³„ëŸ‰ê³¼ p-valueë¥¼ ì¶œë ¥í•˜ì‹œì˜¤.  
</h3>  

<details>  
<summary>ì½”ë“œ</summary>  
from scipy.stats import chisquare<br><br>
<span style="color:gray;"># ê´€ì¸¡ ë¹ˆë„ êµ¬í•˜ê¸°</span><br>
observed = df['ì—°ë ¹ëŒ€'].value_counts().reindex(['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€']).values<br><br>
<span style="color:gray;"># ì „ì²´ ìƒ˜í”Œ ìˆ˜</span><br>
total_n = len(df)<br><br>
<span style="color:gray;"># ì´ë¡ ì  ê¸°ëŒ€ë¹„ìœ¨</span><br>
expected_ratio = {'20ëŒ€': 0.2, '30ëŒ€': 0.3, '40ëŒ€': 0.3, '50ëŒ€': 0.2}<br><br>
<span style="color:gray;"># ê¸°ëŒ€ë¹ˆë„ ê³„ì‚°</span><br>
expected = [total_n * expected_ratio[age] for age in ['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€']]<br><br>
<span style="color:gray;"># ì¹´ì´ì œê³± ì í•©ë„ ê²€ì • ìˆ˜í–‰</span><br>
stat, p = chisquare(f_obs=observed, f_exp=expected)<br><br>
print("Chi-square statistics:", stat)<br>
print("p-value:", p)

<br><br>
>Chi-square statistics: 10.720833333333333<br>
>p-value: 0.013335305093221296
</details>  

<br><br><br><br>



<h3 style="font-weight:normal;">12.</h3>  
<h3 style="font-weight:normal;">  
ì—°ë´‰ì— ì˜í–¥ì„ ì£¼ëŠ” ìš”ì¸ì„ ë¶„ì„í•˜ëŠ” íšŒê·€ëª¨í˜•ì„ êµ¬ì¶•í•˜ì‹œì˜¤. (ë…ë¦½ë³€ìˆ˜ëŠ” ì¢…ì†ë³€ìˆ˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜ë“¤ì„ ì‚¬ìš©í•  ê²ƒ)  
<br>  
ê·¸ë¦¬ê³  ë‹¤ìŒì„ ì¶œë ¥í•˜ì‹œì˜¤:  
</h3>  

<h4 style="font-weight:normal;">- íšŒê·€ê³„ìˆ˜ (Î²) ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- p-value ê°’ ì „ì²´</h4>  
<h4 style="font-weight:normal;">- ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜ (p-value &lt; 0.05ì¸ ë³€ìˆ˜ ê°œìˆ˜)</h4>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import ols<br><br>
model = ols("ì—°ë´‰ ~ C(ì „ê³µ) + C(í•™ìœ„) + ì—°êµ¬ë…„ìˆ˜ + ì—°ê°„ë…¼ë¬¸ìˆ˜", data=df).fit()<br><br>
print(model.params[1:])<br>
print("\n")<br>
print(model.pvalues[1:])<br>
print("\n")<br><br>
pvalues = model.pvalues[1:]<br>
target_num = len(pvalues[pvalues < 0.05])<br>
print("ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜:", target_num)


<br><br>
>coef<br>
>C(ì „ê³µ)[T.ì‚¬íšŒ]   -10.174765<br>
>C(ì „ê³µ)[T.ì¸ë¬¸]    -9.808244<br>
>C(ì „ê³µ)[T.ìì—°]   -10.346413<br>
>C(í•™ìœ„)[T.ì„ì‚¬]    -7.111037<br>
>C(í•™ìœ„)[T.í•™ì‚¬]   -14.510797<br>
>ì—°êµ¬ë…„ìˆ˜            1.265994<br>
>ì—°ê°„ë…¼ë¬¸ìˆ˜           1.199229<br><br>

>pvalue<br>
>C(ì „ê³µ)[T.ì‚¬íšŒ]     4.179690e-57<br>
>C(ì „ê³µ)[T.ì¸ë¬¸]     1.042821e-52<br>
>C(ì „ê³µ)[T.ìì—°]     6.193599e-59<br>
>C(í•™ìœ„)[T.ì„ì‚¬]     8.130448e-41<br>
>C(í•™ìœ„)[T.í•™ì‚¬]    4.824165e-112<br>
>ì—°êµ¬ë…„ìˆ˜            4.837947e-36<br>
>ì—°ê°„ë…¼ë¬¸ìˆ˜           5.287497e-12<br><br>

>ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜: 7
</details>  


<br><br><br><br>



<h3 style="font-weight:normal;">13.</h3>  
<h3 style="font-weight:normal;">  
ì´ì§ì˜ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì„ ì í•©í•˜ê³  ë‹¤ìŒì„ ì¶œë ¥í•˜ì‹œì˜¤:  
</h3>  

<h4 style="font-weight:normal;">- ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜</h4>  
<h4 style="font-weight:normal;">- ì˜¤ì¦ˆë¹„ (odds ratio) ê°’ ì „ì²´ (exp(Î²))</h4>  
<h4 style="font-weight:normal;">- ì”ì°¨ ì´íƒˆë„ (Residual Deviance)</h4>  
<h4 style="font-weight:normal;">- ì´íƒˆë„ ì°¨ì´ ê¸°ë°˜ì˜ ëª¨í˜• ì í•©ë„ ê²€ì • (LR test í†µê³„ëŸ‰)</h4>  

<details>  
<summary>ì½”ë“œ</summary>  
from statsmodels.formula.api import logit<br>
import numpy as np<br><br>
model = logit("ì´ì§ì˜ë„ ~ C(ì „ê³µ) + C(í•™ìœ„) + ì—°êµ¬ë…„ìˆ˜ + ì—°ê°„ë…¼ë¬¸ìˆ˜", data=df).fit()<br><br>
<span style="color:gray;"># ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜ (p-value < 0.05ì¸ ë³€ìˆ˜ ê°œìˆ˜)</span><br>
target_num = len(pvalue[pvalue < 0.05])<br>
print("\n")<br>
print(f"ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜: {target_num}ê°œ")<br>
print("\n")<br><br>
<span style="color:gray;"># ì˜¤ì¦ˆë¹„ (odds ratio) ê°’ ì „ì²´ (exp(Î²))</span><br>
print("odds ratio:\n", np.exp(model.params[1:]))<br>
print("\n")<br><br>
<span style="color:gray;"># ì”ì°¨ ì´íƒˆë„ (Residual Deviance)</span><br>
print("Residual Deviance:", -2 * model.llf)<br>
print("\n")<br><br>
<span style="color:gray;"># ì´íƒˆë„ ì°¨ì´ ê¸°ë°˜ì˜ ëª¨í˜• ì í•©ë„ ê²€ì • (LR test í†µê³„ëŸ‰)</span><br>
print("LR test statistics:", -2 * (model.llnull - model.llf))

<br><br>

>ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ ê°œìˆ˜: 1ê°œ<br><br>
>
>
>odds ratio:<br>
>C(ì „ê³µ)[T.ì‚¬íšŒ]     130.411568<br>
>C(ì „ê³µ)[T.ì¸ë¬¸]     113.323960<br>
>C(ì „ê³µ)[T.ìì—°]      96.562353<br>
>C(í•™ìœ„)[T.ì„ì‚¬]      25.142587<br>
>C(í•™ìœ„)[T.í•™ì‚¬]    1278.187320<br>
>ì—°êµ¬ë…„ìˆ˜              0.561776<br>
>ì—°ê°„ë…¼ë¬¸ìˆ˜             0.491720<br><br>
>
>Residual Deviance: 230.95439446109864<br><br>
>
>LR test statistics: 318.8234774085586
</details>  

</details>

